{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Build a Neural network to predict movie sentiment based on reviews\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "nbpresent": {
     "id": "56bb3cba-260c-4ebe-9ed6-b995b4c72aa3"
    }
   },
   "source": [
    "### Data Set Exploration\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#write a function to print only the first 80 characters\n",
    "def pretty_print_review_and_label(i):\n",
    "    print(labels[i] + \"\\t:\\t\" + reviews[i][:80] + \"...\")\n",
    "\n",
    "g = open('reviews.txt','r') # What we know!\n",
    "reviews = list(map(lambda x:x[:-1],g.readlines()))\n",
    "g.close()\n",
    "\n",
    "g = open('labels.txt','r') # What we WANT to know!\n",
    "labels = list(map(lambda x:x[:-1].upper(),g.readlines()))\n",
    "g.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "nbpresent": {
     "id": "bb95574b-21a0-4213-ae50-34363cf4f87f"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'bromwell high is a cartoon comedy . it ran at the same time as some other programs about school life  such as  teachers  . my   years in the teaching profession lead me to believe that bromwell high  s satire is much closer to reality than is  teachers  . the scramble to survive financially  the insightful students who can see right through their pathetic teachers  pomp  the pettiness of the whole situation  all remind me of the schools i knew and their students . when i saw the episode in which a student repeatedly tried to burn down the school  i immediately recalled . . . . . . . . . at . . . . . . . . . . high . a classic line inspector i  m here to sack one of your teachers . student welcome to bromwell high . i expect that many adults of my age think that bromwell high is far fetched . what a pity that it isn  t   '"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "nbpresent": {
     "id": "e0408810-c424-4ed4-afb9-1735e9ddbd0a"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'POSITIVE'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "labels[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "nbpresent": {
     "id": "e67a709f-234f-4493-bae6-4fb192141ee0"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "labels.txt \t : \t reviews.txt\n",
      "\n",
      "NEGATIVE\t:\tthis movie is terrible but it has some good effects .  ...\n",
      "POSITIVE\t:\tadrian pasdar is excellent is this film . he makes a fascinating woman .  ...\n",
      "NEGATIVE\t:\tcomment this movie is impossible . is terrible  very improbable  bad interpretat...\n",
      "POSITIVE\t:\texcellent episode movie ala pulp fiction .  days   suicides . it doesnt get more...\n",
      "NEGATIVE\t:\tif you haven  t seen this  it  s terrible . it is pure trash . i saw this about ...\n",
      "POSITIVE\t:\tthis schiffer guy is a real genius  the movie is of excellent quality and both e...\n"
     ]
    }
   ],
   "source": [
    "print(\"labels.txt \\t : \\t reviews.txt\\n\")\n",
    "pretty_print_review_and_label(2137)\n",
    "pretty_print_review_and_label(12816)\n",
    "pretty_print_review_and_label(6267)\n",
    "pretty_print_review_and_label(21934)\n",
    "pretty_print_review_and_label(5297)\n",
    "pretty_print_review_and_label(4998)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import Counter\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Create three counters to calculate words frequency for positive sentiment, negative sentiment and total counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create three Counter objects to store positive, negative and total counts\n",
    "positive_counts = Counter()\n",
    "negative_counts = Counter()\n",
    "total_counts = Counter()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "for i in range(len(reviews)):\n",
    "    if(labels[i] == 'POSITIVE'):\n",
    "        for word in reviews[i].split(' '):\n",
    "            positive_counts[word] += 1\n",
    "            total_counts[word] += 1\n",
    "    else:\n",
    "        for word in reviews[i].split(' '):\n",
    "            negative_counts[word] += 1\n",
    "            total_counts[word] += 1\n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 550468),\n",
       " ('the', 173324),\n",
       " ('.', 159654),\n",
       " ('and', 89722),\n",
       " ('a', 83688),\n",
       " ('of', 76855),\n",
       " ('to', 66746),\n",
       " ('is', 57245),\n",
       " ('in', 50215),\n",
       " ('br', 49235),\n",
       " ('it', 48025),\n",
       " ('i', 40743),\n",
       " ('that', 35630),\n",
       " ('this', 35080),\n",
       " ('s', 33815),\n",
       " ('as', 26308),\n",
       " ('with', 23247),\n",
       " ('for', 22416),\n",
       " ('was', 21917),\n",
       " ('film', 20937)]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the counts of the most common words in positive reviews\n",
    "\n",
    "positive_counts.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('', 561462),\n",
       " ('.', 167538),\n",
       " ('the', 163389),\n",
       " ('a', 79321),\n",
       " ('and', 74385),\n",
       " ('of', 69009),\n",
       " ('to', 68974),\n",
       " ('br', 52637),\n",
       " ('is', 50083),\n",
       " ('it', 48327),\n",
       " ('i', 46880),\n",
       " ('in', 43753),\n",
       " ('this', 40920),\n",
       " ('that', 37615),\n",
       " ('s', 31546),\n",
       " ('was', 26291),\n",
       " ('movie', 24965),\n",
       " ('for', 21927),\n",
       " ('but', 21781),\n",
       " ('with', 20878)]"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Examine the counts of the most common words in negative reviews\n",
    "negative_counts.most_common(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### We can see clearly words like space, the , . , and appear a lot in both negative and positive reviews and cannot really  differentiate between both the reviews. In order to understand the importance of words which define these sentiments we need to calculate positive negative ratio to eliminate most common words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create Counter object to store positive/negative ratios\n",
    "pos_neg_ratios = Counter()\n",
    "\n",
    "#       Consider words to be \"common\" if they've been used at least 100 times\n",
    "for word,cnt in list(total_counts.most_common()):\n",
    "    if(cnt >= 100):\n",
    "        pos_neg_ratio = positive_counts[word]/(negative_counts[word]+1)\n",
    "        pos_neg_ratios[word] = pos_neg_ratio"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos-to-neg ratio for 'the' = 1.0607993145235326\n",
      "Pos-to-neg ratio for 'amazing' = 4.022813688212928\n",
      "Pos-to-neg ratio for 'terrible' = 0.17744252873563218\n"
     ]
    }
   ],
   "source": [
    "print(\"Pos-to-neg ratio for 'the' = {}\".format(pos_neg_ratios[\"the\"]))\n",
    "print(\"Pos-to-neg ratio for 'amazing' = {}\".format(pos_neg_ratios[\"amazing\"]))\n",
    "print(\"Pos-to-neg ratio for 'terrible' = {}\".format(pos_neg_ratios[\"terrible\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word Ratio's\n",
    "We can clearly see neutral words like the are around value 1 and negative sentiment words like terrible are close to zero\n",
    "and positve words like amazing are greater than 1. Lets convert the scale of the dataset so that words with score close\n",
    "to zero are neutral and high negative values are negative sentiment and high positive values are positive sentiment"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To achive this we use log transforation\n",
    "for word,ratio in list(pos_neg_ratios.most_common()):\n",
    "    if(ratio > 1):\n",
    "        pos_neg_ratios[word] = np.log(ratio) \n",
    "    else:\n",
    "        pos_neg_ratios[word] = -np.log((1/(ratio + 0.01)))\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Examine the new ratios you've calculated for the same words from before:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pos-to-neg ratio for 'the' = 0.05902269426102881\n",
      "Pos-to-neg ratio for 'amazing' = 1.3919815802404802\n",
      "Pos-to-neg ratio for 'terrible' = -1.6742829939664696\n"
     ]
    }
   ],
   "source": [
    "print(\"Pos-to-neg ratio for 'the' = {}\".format(pos_neg_ratios[\"the\"]))\n",
    "print(\"Pos-to-neg ratio for 'amazing' = {}\".format(pos_neg_ratios[\"amazing\"]))\n",
    "print(\"Pos-to-neg ratio for 'terrible' = {}\".format(pos_neg_ratios[\"terrible\"]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Log Ratios\n",
    "Based on the ouput we can see neutral word 'the' is close to zero and amazing is above 1 and terrrible is below -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('edie', 4.6913478822291435),\n",
       " ('paulie', 4.0775374439057197),\n",
       " ('felix', 3.1527360223636558),\n",
       " ('polanski', 2.8233610476132043),\n",
       " ('matthau', 2.8067217286092401),\n",
       " ('victoria', 2.6810215287142909),\n",
       " ('mildred', 2.6026896854443837),\n",
       " ('gandhi', 2.5389738710582761),\n",
       " ('flawless', 2.451005098112319),\n",
       " ('superbly', 2.2600254785752498),\n",
       " ('perfection', 2.1594842493533721),\n",
       " ('astaire', 2.1400661634962708),\n",
       " ('captures', 2.0386195471595809),\n",
       " ('voight', 2.0301704926730531),\n",
       " ('wonderfully', 2.0218960560332353),\n",
       " ('powell', 1.9783454248084671),\n",
       " ('brosnan', 1.9547990964725592),\n",
       " ('lily', 1.9203768470501485),\n",
       " ('bakshi', 1.9029851043382795),\n",
       " ('lincoln', 1.9014583864844796)]"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# words most frequently seen in a review with a \"POSITIVE\" label\n",
    "pos_neg_ratios.most_common(20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('boll', -4.0778152602708904),\n",
       " ('uwe', -3.9218753018711578),\n",
       " ('seagal', -3.3202501058581921),\n",
       " ('unwatchable', -3.0269848170580955),\n",
       " ('stinker', -2.9876839403711624),\n",
       " ('mst', -2.7753833211707968),\n",
       " ('incoherent', -2.7641396677532537),\n",
       " ('unfunny', -2.5545257844967644),\n",
       " ('waste', -2.4907515123361046),\n",
       " ('blah', -2.4475792789485005),\n",
       " ('horrid', -2.3715779644809971),\n",
       " ('pointless', -2.3451073877136341),\n",
       " ('atrocious', -2.3187369339642556),\n",
       " ('redeeming', -2.2667790015910296),\n",
       " ('prom', -2.2601040980178784),\n",
       " ('drivel', -2.2476029585766928),\n",
       " ('lousy', -2.2118080125207054),\n",
       " ('worst', -2.1930856334332267),\n",
       " ('laughable', -2.172468615469592),\n",
       " ('awful', -2.1385076866397488),\n",
       " ('poorly', -2.1326133844207011),\n",
       " ('wasting', -2.1178155545614512),\n",
       " ('remotely', -2.111046881095167),\n",
       " ('existent', -2.0024805005437076),\n",
       " ('boredom', -1.9241486572738005),\n",
       " ('miserably', -1.9216610938019989),\n",
       " ('sucks', -1.9166645809588516),\n",
       " ('uninspired', -1.9131499212248517),\n",
       " ('lame', -1.9117232884159072),\n",
       " ('insult', -1.9085323769376259)]"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# words most frequently seen in a review with a \"NEGATIVE\" label\n",
    "list(reversed(pos_neg_ratios.most_common()))[0:30]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Common Words Output\n",
    "Based on the above output we can clearly see words like amazing, flawless, superbly, perfection are assigned to positive sentiment\n",
    "and words like unwatchable,stinker,insult, waste are more alligned towards negative sentiment"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Transforming Text into Numbers\n",
    "In order to train neural net to classify sentiment based on movie reviews we need to transform the text into numbers\n",
    "format"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the Input/Output Data\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create a variable vocab which stores the output of all the words and its frequency\n",
    "vocab = total_counts"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bromwell': 8,\n",
       " 'high': 2161,\n",
       " 'is': 107328,\n",
       " 'a': 163009,\n",
       " 'cartoon': 545,\n",
       " 'comedy': 3246,\n",
       " '.': 327192,\n",
       " 'it': 96352,\n",
       " 'ran': 238,\n",
       " 'at': 23513,\n",
       " 'the': 336713,\n",
       " 'same': 4053,\n",
       " 'time': 12724,\n",
       " 'as': 46933,\n",
       " 'some': 15747,\n",
       " 'other': 9163,\n",
       " 'programs': 66,\n",
       " 'about': 17374,\n",
       " 'school': 1659,\n",
       " 'life': 6628,\n",
       " '': 1111930,\n",
       " 'such': 5134,\n",
       " 'teachers': 77,\n",
       " 'my': 12503,\n",
       " 'years': 4517,\n",
       " 'in': 93968,\n",
       " 'teaching': 82,\n",
       " 'profession': 65,\n",
       " 'lead': 1310,\n",
       " 'me': 10773,\n",
       " 'to': 135720,\n",
       " 'believe': 2505,\n",
       " 'that': 73245,\n",
       " 's': 65361,\n",
       " 'satire': 261,\n",
       " 'much': 9763,\n",
       " 'closer': 206,\n",
       " 'reality': 987,\n",
       " 'than': 9919,\n",
       " 'scramble': 6,\n",
       " 'survive': 260,\n",
       " 'financially': 29,\n",
       " 'insightful': 66,\n",
       " 'students': 361,\n",
       " 'who': 21433,\n",
       " 'can': 14654,\n",
       " 'see': 11478,\n",
       " 'right': 3313,\n",
       " 'through': 4969,\n",
       " 'their': 11385,\n",
       " 'pathetic': 468,\n",
       " 'pomp': 9,\n",
       " 'pettiness': 2,\n",
       " 'of': 145864,\n",
       " 'whole': 3078,\n",
       " 'situation': 669,\n",
       " 'all': 23978,\n",
       " 'remind': 157,\n",
       " 'schools': 66,\n",
       " 'i': 87623,\n",
       " 'knew': 898,\n",
       " 'and': 164107,\n",
       " 'when': 14182,\n",
       " 'saw': 3167,\n",
       " 'episode': 1658,\n",
       " 'which': 12047,\n",
       " 'student': 392,\n",
       " 'repeatedly': 119,\n",
       " 'tried': 773,\n",
       " 'burn': 127,\n",
       " 'down': 3728,\n",
       " 'immediately': 462,\n",
       " 'recalled': 18,\n",
       " 'classic': 1829,\n",
       " 'line': 1868,\n",
       " 'inspector': 162,\n",
       " 'm': 4998,\n",
       " 'here': 5767,\n",
       " 'sack': 44,\n",
       " 'one': 26789,\n",
       " 'your': 5686,\n",
       " 'welcome': 214,\n",
       " 'expect': 1178,\n",
       " 'many': 6675,\n",
       " 'adults': 376,\n",
       " 'age': 1119,\n",
       " 'think': 7298,\n",
       " 'far': 2977,\n",
       " 'fetched': 103,\n",
       " 'what': 16159,\n",
       " 'pity': 229,\n",
       " 'isn': 3177,\n",
       " 't': 34081,\n",
       " 'story': 11988,\n",
       " 'man': 5976,\n",
       " 'has': 16790,\n",
       " 'unnatural': 46,\n",
       " 'feelings': 395,\n",
       " 'for': 44343,\n",
       " 'pig': 102,\n",
       " 'starts': 1220,\n",
       " 'out': 17113,\n",
       " 'with': 44125,\n",
       " 'opening': 979,\n",
       " 'scene': 5383,\n",
       " 'terrific': 433,\n",
       " 'example': 1371,\n",
       " 'absurd': 306,\n",
       " 'formal': 27,\n",
       " 'orchestra': 47,\n",
       " 'audience': 2198,\n",
       " 'turned': 925,\n",
       " 'into': 9111,\n",
       " 'an': 21560,\n",
       " 'insane': 241,\n",
       " 'violent': 523,\n",
       " 'mob': 157,\n",
       " 'by': 22546,\n",
       " 'crazy': 657,\n",
       " 'chantings': 1,\n",
       " 'singers': 79,\n",
       " 'unfortunately': 1353,\n",
       " 'stays': 182,\n",
       " 'no': 12717,\n",
       " 'general': 764,\n",
       " 'narrative': 424,\n",
       " 'eventually': 720,\n",
       " 'making': 2960,\n",
       " 'just': 17771,\n",
       " 'too': 7833,\n",
       " 'off': 6030,\n",
       " 'putting': 369,\n",
       " 'even': 12651,\n",
       " 'those': 4697,\n",
       " 'from': 20498,\n",
       " 'era': 614,\n",
       " 'should': 5041,\n",
       " 'be': 26957,\n",
       " 'cryptic': 18,\n",
       " 'dialogue': 1542,\n",
       " 'would': 12436,\n",
       " 'make': 8025,\n",
       " 'shakespeare': 296,\n",
       " 'seem': 2175,\n",
       " 'easy': 802,\n",
       " 'third': 738,\n",
       " 'grader': 28,\n",
       " 'on': 34200,\n",
       " 'technical': 305,\n",
       " 'level': 963,\n",
       " 'better': 5739,\n",
       " 'you': 34230,\n",
       " 'might': 2918,\n",
       " 'good': 15143,\n",
       " 'cinematography': 985,\n",
       " 'future': 899,\n",
       " 'great': 9059,\n",
       " 'vilmos': 4,\n",
       " 'zsigmond': 4,\n",
       " 'stars': 1697,\n",
       " 'sally': 135,\n",
       " 'kirkland': 24,\n",
       " 'frederic': 13,\n",
       " 'forrest': 42,\n",
       " 'seen': 6679,\n",
       " 'briefly': 136,\n",
       " 'homelessness': 7,\n",
       " 'or': 18004,\n",
       " 'houselessness': 1,\n",
       " 'george': 864,\n",
       " 'carlin': 12,\n",
       " 'stated': 132,\n",
       " 'been': 9289,\n",
       " 'issue': 287,\n",
       " 'but': 42603,\n",
       " 'never': 6485,\n",
       " 'plan': 421,\n",
       " 'help': 1896,\n",
       " 'street': 699,\n",
       " 'were': 10783,\n",
       " 'once': 2329,\n",
       " 'considered': 484,\n",
       " 'human': 1596,\n",
       " 'did': 6296,\n",
       " 'everything': 2325,\n",
       " 'going': 4102,\n",
       " 'work': 4373,\n",
       " 'vote': 222,\n",
       " 'matter': 1127,\n",
       " 'most': 8783,\n",
       " 'people': 9285,\n",
       " 'homeless': 140,\n",
       " 'lost': 1552,\n",
       " 'cause': 535,\n",
       " 'while': 5317,\n",
       " 'worrying': 41,\n",
       " 'things': 3688,\n",
       " 'racism': 153,\n",
       " 'war': 2051,\n",
       " 'iraq': 85,\n",
       " 'pressuring': 5,\n",
       " 'kids': 1843,\n",
       " 'succeed': 150,\n",
       " 'technology': 245,\n",
       " 'elections': 10,\n",
       " 'inflation': 11,\n",
       " 'if': 16803,\n",
       " 'they': 22906,\n",
       " 'll': 2893,\n",
       " 'next': 1717,\n",
       " 'end': 5650,\n",
       " 'up': 13291,\n",
       " 'streets': 269,\n",
       " 'br': 101872,\n",
       " 'given': 1848,\n",
       " 'bet': 244,\n",
       " 'live': 1552,\n",
       " 'month': 148,\n",
       " 'without': 3266,\n",
       " 'luxuries': 4,\n",
       " 'had': 11290,\n",
       " 'home': 1877,\n",
       " 'entertainment': 879,\n",
       " 'sets': 852,\n",
       " 'bathroom': 114,\n",
       " 'pictures': 454,\n",
       " 'wall': 364,\n",
       " 'computer': 470,\n",
       " 'treasure': 202,\n",
       " 'like': 20276,\n",
       " 'goddard': 8,\n",
       " 'bolt': 23,\n",
       " 'lesson': 256,\n",
       " 'mel': 119,\n",
       " 'brooks': 169,\n",
       " 'directs': 103,\n",
       " 'plays': 2213,\n",
       " 'rich': 587,\n",
       " 'world': 3833,\n",
       " 'until': 1776,\n",
       " 'deciding': 52,\n",
       " 'sissy': 82,\n",
       " 'rival': 161,\n",
       " 'jeffery': 16,\n",
       " 'tambor': 9,\n",
       " 'he': 30138,\n",
       " 'thirty': 141,\n",
       " 'days': 1268,\n",
       " 'succeeds': 167,\n",
       " 'do': 9177,\n",
       " 'wants': 1288,\n",
       " 'project': 491,\n",
       " 'more': 14251,\n",
       " 'buildings': 94,\n",
       " 'where': 6392,\n",
       " 'thrown': 409,\n",
       " 'bracelet': 10,\n",
       " 'his': 29374,\n",
       " 'leg': 112,\n",
       " 'monitor': 29,\n",
       " 'every': 3979,\n",
       " 'move': 726,\n",
       " 'step': 373,\n",
       " 'sidewalk': 57,\n",
       " 'nickname': 18,\n",
       " 'pepto': 4,\n",
       " 'vagrant': 3,\n",
       " 'after': 7638,\n",
       " 'written': 1616,\n",
       " 'forehead': 23,\n",
       " 'meets': 677,\n",
       " 'characters': 7160,\n",
       " 'including': 1052,\n",
       " 'woman': 2795,\n",
       " 'name': 1604,\n",
       " 'molly': 89,\n",
       " 'lesley': 13,\n",
       " 'ann': 288,\n",
       " 'warren': 117,\n",
       " 'ex': 468,\n",
       " 'dancer': 149,\n",
       " 'got': 3587,\n",
       " 'divorce': 106,\n",
       " 'before': 4324,\n",
       " 'losing': 220,\n",
       " 'her': 18421,\n",
       " 'pals': 36,\n",
       " 'sailor': 53,\n",
       " 'howard': 260,\n",
       " 'morris': 98,\n",
       " 'fumes': 4,\n",
       " 'teddy': 36,\n",
       " 'wilson': 200,\n",
       " 'are': 29430,\n",
       " 'already': 1381,\n",
       " 'used': 1879,\n",
       " 're': 4504,\n",
       " 'survivors': 101,\n",
       " 'not': 30626,\n",
       " 'reaching': 95,\n",
       " 'mutual': 64,\n",
       " 'agreements': 4,\n",
       " 'being': 6610,\n",
       " 'fight': 1148,\n",
       " 'flight': 177,\n",
       " 'kill': 1234,\n",
       " 'killed': 1111,\n",
       " 'love': 6453,\n",
       " 'connection': 258,\n",
       " 'between': 3390,\n",
       " 'wasn': 2308,\n",
       " 'necessary': 324,\n",
       " 'plot': 6586,\n",
       " 'found': 2573,\n",
       " 'stinks': 97,\n",
       " 'observant': 14,\n",
       " 'films': 6890,\n",
       " 'prior': 192,\n",
       " 'shows': 2307,\n",
       " 'tender': 101,\n",
       " 'side': 1276,\n",
       " 'compared': 538,\n",
       " 'slapstick': 176,\n",
       " 'blazing': 46,\n",
       " 'saddles': 24,\n",
       " 'young': 3660,\n",
       " 'frankenstein': 92,\n",
       " 'spaceballs': 10,\n",
       " 'show': 6294,\n",
       " 'having': 2546,\n",
       " 'something': 5077,\n",
       " 'valuable': 93,\n",
       " 'day': 2746,\n",
       " 'hand': 1257,\n",
       " 'stupid': 1701,\n",
       " 'don': 8804,\n",
       " 'know': 6167,\n",
       " 'money': 2361,\n",
       " 'maybe': 2341,\n",
       " 'give': 3376,\n",
       " 'instead': 2190,\n",
       " 'using': 801,\n",
       " 'monopoly': 12,\n",
       " 'this': 76000,\n",
       " 'film': 40155,\n",
       " 'will': 9211,\n",
       " 'inspire': 65,\n",
       " 'others': 1595,\n",
       " 'airport': 93,\n",
       " 'brand': 135,\n",
       " 'new': 4312,\n",
       " 'luxury': 39,\n",
       " 'plane': 322,\n",
       " 'loaded': 85,\n",
       " 'paintings': 69,\n",
       " 'belonging': 23,\n",
       " 'businessman': 83,\n",
       " 'philip': 161,\n",
       " 'stevens': 94,\n",
       " 'james': 1068,\n",
       " 'stewart': 468,\n",
       " 'flying': 357,\n",
       " 'them': 7970,\n",
       " 'bunch': 813,\n",
       " 'vip': 5,\n",
       " 'estate': 128,\n",
       " 'preparation': 27,\n",
       " 'opened': 155,\n",
       " 'public': 564,\n",
       " 'museum': 96,\n",
       " 'also': 9158,\n",
       " 'board': 250,\n",
       " 'daughter': 1138,\n",
       " 'julie': 174,\n",
       " 'kathleen': 50,\n",
       " 'quinlan': 2,\n",
       " 'son': 1356,\n",
       " 'jetliner': 1,\n",
       " 'takes': 2192,\n",
       " 'planned': 101,\n",
       " 'mid': 319,\n",
       " 'air': 639,\n",
       " 'hi': 61,\n",
       " 'jacked': 9,\n",
       " 'co': 602,\n",
       " 'pilot': 300,\n",
       " 'chambers': 7,\n",
       " 'robert': 951,\n",
       " 'foxworth': 6,\n",
       " 'two': 6906,\n",
       " 'accomplice': 23,\n",
       " 'banker': 17,\n",
       " 'monte': 15,\n",
       " 'markham': 11,\n",
       " 'michael': 1333,\n",
       " 'pataki': 8,\n",
       " 'knock': 139,\n",
       " 'passengers': 58,\n",
       " 'crew': 569,\n",
       " 'sleeping': 179,\n",
       " 'gas': 195,\n",
       " 'steal': 247,\n",
       " 'cargo': 23,\n",
       " 'land': 362,\n",
       " 'disused': 8,\n",
       " 'strip': 143,\n",
       " 'isolated': 98,\n",
       " 'island': 536,\n",
       " 'descent': 89,\n",
       " 'almost': 3140,\n",
       " 'hits': 272,\n",
       " 'oil': 142,\n",
       " 'rig': 12,\n",
       " 'ocean': 103,\n",
       " 'loses': 263,\n",
       " 'control': 511,\n",
       " 'sending': 69,\n",
       " 'crashing': 56,\n",
       " 'sea': 264,\n",
       " 'sinks': 41,\n",
       " 'bottom': 423,\n",
       " 'bang': 108,\n",
       " 'middle': 956,\n",
       " 'bermuda': 3,\n",
       " 'triangle': 65,\n",
       " 'short': 1866,\n",
       " 'supply': 60,\n",
       " 'water': 547,\n",
       " 'leaking': 4,\n",
       " 'flown': 14,\n",
       " 'over': 6333,\n",
       " 'miles': 260,\n",
       " 'course': 2506,\n",
       " 'problems': 887,\n",
       " 'mount': 22,\n",
       " 'survivor': 85,\n",
       " 'await': 21,\n",
       " 'fast': 897,\n",
       " 'running': 992,\n",
       " 'known': 1079,\n",
       " 'under': 1368,\n",
       " 'slightly': 541,\n",
       " 'different': 2382,\n",
       " 'tile': 4,\n",
       " 'second': 1962,\n",
       " 'sequel': 818,\n",
       " 'smash': 54,\n",
       " 'hit': 1087,\n",
       " 'disaster': 320,\n",
       " 'thriller': 897,\n",
       " 'was': 48208,\n",
       " 'directed': 1204,\n",
       " 'jerry': 379,\n",
       " 'jameson': 34,\n",
       " 'again': 4007,\n",
       " 'predecessors': 39,\n",
       " 'say': 5396,\n",
       " 'any': 7660,\n",
       " 'sort': 1472,\n",
       " 'forgotten': 354,\n",
       " 'entertaining': 1443,\n",
       " 'although': 2537,\n",
       " 'necessarily': 180,\n",
       " 'reasons': 596,\n",
       " 'three': 2295,\n",
       " 'have': 27731,\n",
       " 'so': 20617,\n",
       " 'actually': 4239,\n",
       " 'liked': 1516,\n",
       " 'best': 6413,\n",
       " 'favourite': 329,\n",
       " 'nice': 2012,\n",
       " 'jacking': 3,\n",
       " 'then': 8119,\n",
       " 'didn': 4318,\n",
       " 'sinking': 60,\n",
       " 'makers': 490,\n",
       " 'trying': 2473,\n",
       " 'cross': 325,\n",
       " 'original': 3376,\n",
       " 'another': 4329,\n",
       " 'popular': 550,\n",
       " 'flick': 1258,\n",
       " 'period': 767,\n",
       " 'poseidon': 3,\n",
       " 'adventure': 510,\n",
       " 'submerged': 10,\n",
       " 'stark': 76,\n",
       " 'dilemma': 59,\n",
       " 'facing': 96,\n",
       " 'trapped': 188,\n",
       " 'inside': 600,\n",
       " 'either': 1866,\n",
       " 'suffocate': 2,\n",
       " 'runs': 513,\n",
       " 'drown': 26,\n",
       " 'floods': 6,\n",
       " 'doors': 125,\n",
       " 'decent': 1157,\n",
       " 'idea': 2043,\n",
       " 'could': 7923,\n",
       " 'made': 8364,\n",
       " 'little': 6437,\n",
       " 'bad': 9308,\n",
       " 'unsympathetic': 53,\n",
       " 'character': 7020,\n",
       " 'dull': 816,\n",
       " 'lethargic': 22,\n",
       " 'set': 2454,\n",
       " 'pieces': 424,\n",
       " 'real': 4738,\n",
       " 'lack': 1058,\n",
       " 'danger': 214,\n",
       " 'suspense': 741,\n",
       " 'tension': 542,\n",
       " 'means': 761,\n",
       " 'missed': 565,\n",
       " 'opportunity': 393,\n",
       " 'rather': 2734,\n",
       " 'sluggish': 20,\n",
       " 'keeps': 642,\n",
       " 'entertained': 237,\n",
       " 'odd': 582,\n",
       " 'minutes': 2953,\n",
       " 'happens': 1081,\n",
       " 'there': 18832,\n",
       " 'urgency': 36,\n",
       " 'thought': 3437,\n",
       " 'navy': 162,\n",
       " 'become': 1543,\n",
       " 'involved': 1077,\n",
       " 'pick': 452,\n",
       " 'few': 4076,\n",
       " 'shots': 948,\n",
       " 'huge': 945,\n",
       " 'ships': 79,\n",
       " 'helicopters': 27,\n",
       " 'lacking': 277,\n",
       " 'kennedy': 107,\n",
       " 'jinxed': 2,\n",
       " 'airline': 22,\n",
       " 'worker': 129,\n",
       " 'joe': 691,\n",
       " 'patroni': 2,\n",
       " 'back': 4971,\n",
       " 'only': 11918,\n",
       " 'gets': 3204,\n",
       " 'couple': 1718,\n",
       " 'scenes': 5212,\n",
       " 'barely': 482,\n",
       " 'says': 1110,\n",
       " 'anything': 2949,\n",
       " 'preferring': 13,\n",
       " 'look': 4147,\n",
       " 'worried': 117,\n",
       " 'background': 619,\n",
       " 'video': 1731,\n",
       " 'theatrical': 228,\n",
       " 'version': 2157,\n",
       " 'run': 1219,\n",
       " 'us': 3790,\n",
       " 'tv': 2782,\n",
       " 'versions': 253,\n",
       " 'add': 810,\n",
       " 'extra': 315,\n",
       " 'hour': 1187,\n",
       " 'footage': 651,\n",
       " 'credits': 673,\n",
       " 'sequence': 875,\n",
       " 'flashbacks': 240,\n",
       " 'flesh': 247,\n",
       " 'longer': 477,\n",
       " 'rescue': 231,\n",
       " 'discovery': 116,\n",
       " 'dead': 1877,\n",
       " 'bodies': 217,\n",
       " 'navigator': 3,\n",
       " 'am': 2807,\n",
       " 'sure': 2686,\n",
       " 'sit': 710,\n",
       " 'near': 824,\n",
       " 'cut': 1035,\n",
       " 'expected': 704,\n",
       " 'dated': 267,\n",
       " 'badly': 663,\n",
       " 'horrible': 1201,\n",
       " 'fashions': 43,\n",
       " 'interior': 47,\n",
       " 'design': 342,\n",
       " 'choices': 171,\n",
       " 'toy': 169,\n",
       " 'model': 241,\n",
       " 'effects': 2204,\n",
       " 'aren': 886,\n",
       " 'along': 1775,\n",
       " 'sequels': 224,\n",
       " 'pride': 151,\n",
       " 'place': 2411,\n",
       " 'razzie': 27,\n",
       " 'award': 419,\n",
       " 'hall': 221,\n",
       " 'shame': 671,\n",
       " 'lots': 796,\n",
       " 'worse': 1469,\n",
       " 'reckon': 26,\n",
       " 'harsh': 200,\n",
       " 'action': 3355,\n",
       " 'pace': 551,\n",
       " 'slow': 1132,\n",
       " 'excitement': 220,\n",
       " 'generated': 85,\n",
       " 'pretty': 3664,\n",
       " 'properly': 167,\n",
       " 'production': 1790,\n",
       " 'values': 467,\n",
       " 'alright': 185,\n",
       " 'nothing': 4290,\n",
       " 'spectacular': 248,\n",
       " 'acting': 6493,\n",
       " 'oscar': 861,\n",
       " 'winner': 232,\n",
       " 'jack': 922,\n",
       " 'lemmon': 109,\n",
       " 'said': 2196,\n",
       " 'since': 2907,\n",
       " 'mistake': 426,\n",
       " 'star': 2083,\n",
       " 'looks': 2413,\n",
       " 'old': 4526,\n",
       " 'frail': 25,\n",
       " 'lee': 814,\n",
       " 'grant': 262,\n",
       " 'drunk': 292,\n",
       " 'sir': 183,\n",
       " 'christopher': 414,\n",
       " 'plenty': 632,\n",
       " 'familiar': 538,\n",
       " 'faces': 345,\n",
       " 'orientated': 8,\n",
       " 'ideas': 595,\n",
       " 'behind': 1279,\n",
       " 'bit': 3055,\n",
       " 'silly': 889,\n",
       " 'bland': 274,\n",
       " 'direction': 1385,\n",
       " 'doesn': 4536,\n",
       " 'though': 4566,\n",
       " 'sunken': 14,\n",
       " 'shouldn': 338,\n",
       " 'boring': 1811,\n",
       " 'followed': 373,\n",
       " 'concorde': 7,\n",
       " 'brilliant': 1196,\n",
       " 'dramatic': 667,\n",
       " 'hobo': 8,\n",
       " 'lady': 848,\n",
       " 'ever': 5997,\n",
       " 'clothes': 328,\n",
       " 'warehouse': 44,\n",
       " 'none': 1030,\n",
       " 'corn': 61,\n",
       " 'face': 1645,\n",
       " 'take': 3509,\n",
       " 'lawyers': 35,\n",
       " 'superb': 671,\n",
       " 'accused': 123,\n",
       " 'turncoat': 4,\n",
       " 'selling': 129,\n",
       " 'boss': 416,\n",
       " 'dishonest': 21,\n",
       " 'lawyer': 210,\n",
       " 'shrugs': 6,\n",
       " 'indifferently': 3,\n",
       " 'funny': 4289,\n",
       " 'words': 884,\n",
       " 'jeffrey': 107,\n",
       " 'favorite': 1232,\n",
       " 'later': 2199,\n",
       " 'larry': 183,\n",
       " 'sanders': 56,\n",
       " 'fantastic': 797,\n",
       " 'mad': 499,\n",
       " 'millionaire': 79,\n",
       " 'crush': 102,\n",
       " 'ghetto': 55,\n",
       " 'malevolent': 28,\n",
       " 'usual': 965,\n",
       " 'hospital': 357,\n",
       " 'invade': 12,\n",
       " 'demolition': 17,\n",
       " 'site': 244,\n",
       " 'classics': 233,\n",
       " 'legs': 160,\n",
       " 'big': 3477,\n",
       " 'diggers': 14,\n",
       " 'fighting': 607,\n",
       " 'bleeds': 6,\n",
       " 'movie': 44039,\n",
       " 'each': 2580,\n",
       " 'quite': 3739,\n",
       " 'often': 1601,\n",
       " 'lacked': 121,\n",
       " 'couldn': 1493,\n",
       " 'put': 2381,\n",
       " 'finger': 97,\n",
       " 'first': 9061,\n",
       " 'charisma': 138,\n",
       " 'part': 4040,\n",
       " 'leading': 622,\n",
       " 'actress': 1219,\n",
       " 'inevitably': 82,\n",
       " 'translated': 74,\n",
       " 'chemistry': 490,\n",
       " 'she': 14223,\n",
       " 'shared': 75,\n",
       " 'screen': 2493,\n",
       " 'romantic': 856,\n",
       " 'came': 1673,\n",
       " 'across': 971,\n",
       " 'merely': 359,\n",
       " 'actors': 4484,\n",
       " 'play': 2238,\n",
       " 'very': 14069,\n",
       " 'well': 10659,\n",
       " 'director': 4445,\n",
       " 'miscalculated': 2,\n",
       " 'needed': 683,\n",
       " 'screenplay': 695,\n",
       " 'exactly': 995,\n",
       " 'chef': 36,\n",
       " 'seemed': 1363,\n",
       " 'enamored': 15,\n",
       " 'culinary': 4,\n",
       " 'skills': 267,\n",
       " 'restaurant': 119,\n",
       " 'ultimately': 521,\n",
       " 'himself': 2159,\n",
       " 'youthful': 61,\n",
       " 'exploits': 62,\n",
       " 'anybody': 310,\n",
       " 'else': 2000,\n",
       " 'convinced': 216,\n",
       " 'princess': 197,\n",
       " 'disappointed': 917,\n",
       " 'forget': 718,\n",
       " 'nominated': 222,\n",
       " 'judge': 279,\n",
       " 'yourself': 989,\n",
       " 'easily': 892,\n",
       " 'underrated': 236,\n",
       " 'inn': 23,\n",
       " 'cannon': 77,\n",
       " 'its': 8277,\n",
       " 'flawed': 156,\n",
       " 'does': 5940,\n",
       " 'realistic': 758,\n",
       " 'view': 964,\n",
       " 'unlike': 584,\n",
       " 'how': 8901,\n",
       " 'citizen': 125,\n",
       " 'kane': 135,\n",
       " 'gave': 1217,\n",
       " 'lounge': 13,\n",
       " 'titanic': 190,\n",
       " 'italians': 35,\n",
       " 'idiots': 118,\n",
       " 'jokes': 976,\n",
       " 'fall': 770,\n",
       " 'flat': 577,\n",
       " 'still': 5623,\n",
       " 'lovable': 144,\n",
       " 'way': 8025,\n",
       " 'comedies': 439,\n",
       " 'pull': 342,\n",
       " 'traditionally': 23,\n",
       " 'reviled': 7,\n",
       " 'members': 552,\n",
       " 'society': 676,\n",
       " 'truly': 1743,\n",
       " 'impressive': 500,\n",
       " 'fisher': 129,\n",
       " 'king': 993,\n",
       " 'crap': 1039,\n",
       " 'complaint': 139,\n",
       " 'cast': 3827,\n",
       " 'someone': 2337,\n",
       " 'writer': 1152,\n",
       " 'sorry': 771,\n",
       " 'everyone': 2223,\n",
       " 'supposed': 1516,\n",
       " 'art': 1289,\n",
       " 'wow': 432,\n",
       " 'handed': 182,\n",
       " 'guns': 283,\n",
       " 'screening': 173,\n",
       " 'blow': 202,\n",
       " 'brains': 109,\n",
       " 'watch': 6974,\n",
       " 'photographic': 21,\n",
       " 'excellent': 2071,\n",
       " 'painful': 417,\n",
       " 'absence': 116,\n",
       " 'sound': 1320,\n",
       " 'track': 399,\n",
       " 'brutal': 303,\n",
       " 'loooonnnnng': 1,\n",
       " 'long': 3451,\n",
       " 'sitting': 451,\n",
       " 'talking': 955,\n",
       " 'especially': 2535,\n",
       " 'complaining': 76,\n",
       " 'really': 11738,\n",
       " 'hard': 2668,\n",
       " 'getting': 1627,\n",
       " 'performances': 1821,\n",
       " 'dark': 1381,\n",
       " 'sombre': 16,\n",
       " 'uninspired': 123,\n",
       " 'stuff': 1174,\n",
       " 'thing': 4528,\n",
       " 'maureen': 50,\n",
       " 'stapleton': 16,\n",
       " 'red': 818,\n",
       " 'dress': 181,\n",
       " 'dancing': 531,\n",
       " 'otherwise': 671,\n",
       " 'ripoff': 46,\n",
       " 'bergman': 96,\n",
       " 'fan': 1911,\n",
       " 'f': 420,\n",
       " 'anyone': 2632,\n",
       " 'enjoyed': 1246,\n",
       " 'hours': 983,\n",
       " 'lying': 146,\n",
       " 'typical': 778,\n",
       " 'less': 2001,\n",
       " 'movies': 7666,\n",
       " 'followable': 4,\n",
       " 'leslie': 173,\n",
       " 'rated': 506,\n",
       " 'moments': 1665,\n",
       " 'fleshed': 56,\n",
       " 'probably': 2842,\n",
       " 'room': 944,\n",
       " 'worth': 2278,\n",
       " 'price': 295,\n",
       " 'rent': 721,\n",
       " 'overall': 1437,\n",
       " 'job': 2277,\n",
       " 'characteristic': 45,\n",
       " 'speaking': 405,\n",
       " 'directly': 193,\n",
       " 'actor': 2388,\n",
       " 'fume': 2,\n",
       " 'both': 3406,\n",
       " 'played': 2588,\n",
       " 'parts': 1191,\n",
       " 'parents': 763,\n",
       " 'took': 1100,\n",
       " 'theater': 828,\n",
       " 'interiors': 41,\n",
       " 'watched': 2236,\n",
       " 'we': 10859,\n",
       " 'walked': 195,\n",
       " 'recently': 579,\n",
       " 'lived': 382,\n",
       " 'rest': 1803,\n",
       " 'pretentious': 269,\n",
       " 'ponderous': 26,\n",
       " 'painfully': 240,\n",
       " 'piece': 1537,\n",
       " 'wine': 55,\n",
       " 'cheese': 158,\n",
       " 'tripe': 78,\n",
       " 'woody': 240,\n",
       " 'allen': 404,\n",
       " 'directors': 676,\n",
       " 'worst': 2732,\n",
       " 'career': 1007,\n",
       " 'unmistakable': 18,\n",
       " 'style': 1601,\n",
       " 'ingmar': 17,\n",
       " 'berman': 13,\n",
       " 'gives': 1577,\n",
       " 'angular': 8,\n",
       " 'muted': 35,\n",
       " 'insight': 187,\n",
       " 'lives': 1393,\n",
       " 'family': 3202,\n",
       " 'wrought': 23,\n",
       " 'psychological': 266,\n",
       " 'damage': 108,\n",
       " 'caused': 237,\n",
       " 'estrangement': 7,\n",
       " 'non': 899,\n",
       " 'halitosis': 1,\n",
       " 'whatever': 732,\n",
       " 'intentionally': 90,\n",
       " 'comic': 901,\n",
       " 'relief': 242,\n",
       " 'music': 3054,\n",
       " 'drenched': 17,\n",
       " 'shadowy': 32,\n",
       " 'pathos': 53,\n",
       " 'defined': 87,\n",
       " 'expressionist': 20,\n",
       " 'nature': 709,\n",
       " 'improvisational': 6,\n",
       " 'method': 103,\n",
       " 'illicit': 17,\n",
       " 'pronounced': 30,\n",
       " 'depth': 511,\n",
       " 'meaning': 473,\n",
       " 'truth': 700,\n",
       " 'beyond': 866,\n",
       " 'simply': 1965,\n",
       " 'sympathy': 199,\n",
       " 'felt': 1528,\n",
       " 'contempt': 63,\n",
       " 'parade': 78,\n",
       " 'shuffling': 11,\n",
       " 'whining': 56,\n",
       " 'nicotine': 4,\n",
       " 'stained': 14,\n",
       " 'martyrs': 4,\n",
       " 'perpetual': 23,\n",
       " 'quest': 183,\n",
       " 'identity': 256,\n",
       " 'amid': 39,\n",
       " 'backdrop': 105,\n",
       " 'cosmopolitan': 7,\n",
       " 'affluence': 2,\n",
       " 'baked': 41,\n",
       " 'brie': 2,\n",
       " 'intelligentsia': 4,\n",
       " 'looms': 9,\n",
       " 'fart': 47,\n",
       " 'speaks': 202,\n",
       " 'affected': 113,\n",
       " 'platitudes': 13,\n",
       " 'elevated': 26,\n",
       " 'language': 531,\n",
       " 'cigarettes': 26,\n",
       " 'struggling': 197,\n",
       " 'desperate': 324,\n",
       " 'find': 4132,\n",
       " 'understanding': 275,\n",
       " 'goes': 2442,\n",
       " 'point': 3224,\n",
       " 'want': 3703,\n",
       " 'slap': 122,\n",
       " 'resolution': 130,\n",
       " 'interminable': 31,\n",
       " 'introspective': 18,\n",
       " 'babble': 19,\n",
       " 'drama': 1411,\n",
       " 'taken': 987,\n",
       " 'extreme': 351,\n",
       " 'ability': 454,\n",
       " 'connect': 117,\n",
       " 'chose': 202,\n",
       " 'immersed': 33,\n",
       " 'themselves': 1184,\n",
       " 'feel': 2951,\n",
       " 'left': 2125,\n",
       " 'reason': 2323,\n",
       " 'self': 1185,\n",
       " 'indulgent': 80,\n",
       " 'spiritually': 11,\n",
       " 'draining': 18,\n",
       " 'insistence': 19,\n",
       " 'promoting': 38,\n",
       " 'message': 829,\n",
       " 'prozac': 6,\n",
       " 'prose': 14,\n",
       " 'distorted': 40,\n",
       " 'techniques': 136,\n",
       " 'jettisons': 3,\n",
       " 'past': 1263,\n",
       " 'relevance': 50,\n",
       " 'highly': 1148,\n",
       " 'recommend': 1668,\n",
       " 'feeling': 1145,\n",
       " 'happy': 965,\n",
       " 'need': 1807,\n",
       " 'death': 1907,\n",
       " 'let': 2339,\n",
       " 'pretend': 112,\n",
       " 'happened': 1076,\n",
       " 'comedic': 315,\n",
       " 'robin': 248,\n",
       " 'williams': 344,\n",
       " 'nor': 686,\n",
       " 'quirky': 174,\n",
       " 'recent': 511,\n",
       " 'fame': 229,\n",
       " 'hybrid': 55,\n",
       " 'dramatization': 17,\n",
       " 'mixed': 287,\n",
       " 'per': 161,\n",
       " ...}"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dict(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "74074\n"
     ]
    }
   ],
   "source": [
    "## There are 74074 different words used in the reviews\n",
    "vocab_size = len(vocab)\n",
    "print(vocab_size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Layers in Neural Nets\n",
    "layer_0 - Input Layer - 'Text transformed into numbers',\n",
    "layer_1 - Hidden layer,\n",
    "layer_2 - Output layer - 'Positive or Negative Sentiment'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create layer_0 matrix with dimensions 1 by vocab_size, initially filled with zeros\n",
    "layer_0 = np.zeros((1,vocab_size))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1, 74074)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "layer_0.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'bromwell': 0,\n",
       " 'high': 1,\n",
       " 'is': 2,\n",
       " 'a': 3,\n",
       " 'cartoon': 4,\n",
       " 'comedy': 5,\n",
       " '.': 6,\n",
       " 'it': 7,\n",
       " 'ran': 8,\n",
       " 'at': 9,\n",
       " 'the': 10,\n",
       " 'same': 11,\n",
       " 'time': 12,\n",
       " 'as': 13,\n",
       " 'some': 14,\n",
       " 'other': 15,\n",
       " 'programs': 16,\n",
       " 'about': 17,\n",
       " 'school': 18,\n",
       " 'life': 19,\n",
       " '': 20,\n",
       " 'such': 21,\n",
       " 'teachers': 22,\n",
       " 'my': 23,\n",
       " 'years': 24,\n",
       " 'in': 25,\n",
       " 'teaching': 26,\n",
       " 'profession': 27,\n",
       " 'lead': 28,\n",
       " 'me': 29,\n",
       " 'to': 30,\n",
       " 'believe': 31,\n",
       " 'that': 32,\n",
       " 's': 33,\n",
       " 'satire': 34,\n",
       " 'much': 35,\n",
       " 'closer': 36,\n",
       " 'reality': 37,\n",
       " 'than': 38,\n",
       " 'scramble': 39,\n",
       " 'survive': 40,\n",
       " 'financially': 41,\n",
       " 'insightful': 42,\n",
       " 'students': 43,\n",
       " 'who': 44,\n",
       " 'can': 45,\n",
       " 'see': 46,\n",
       " 'right': 47,\n",
       " 'through': 48,\n",
       " 'their': 49,\n",
       " 'pathetic': 50,\n",
       " 'pomp': 51,\n",
       " 'pettiness': 52,\n",
       " 'of': 53,\n",
       " 'whole': 54,\n",
       " 'situation': 55,\n",
       " 'all': 56,\n",
       " 'remind': 57,\n",
       " 'schools': 58,\n",
       " 'i': 59,\n",
       " 'knew': 60,\n",
       " 'and': 61,\n",
       " 'when': 62,\n",
       " 'saw': 63,\n",
       " 'episode': 64,\n",
       " 'which': 65,\n",
       " 'student': 66,\n",
       " 'repeatedly': 67,\n",
       " 'tried': 68,\n",
       " 'burn': 69,\n",
       " 'down': 70,\n",
       " 'immediately': 71,\n",
       " 'recalled': 72,\n",
       " 'classic': 73,\n",
       " 'line': 74,\n",
       " 'inspector': 75,\n",
       " 'm': 76,\n",
       " 'here': 77,\n",
       " 'sack': 78,\n",
       " 'one': 79,\n",
       " 'your': 80,\n",
       " 'welcome': 81,\n",
       " 'expect': 82,\n",
       " 'many': 83,\n",
       " 'adults': 84,\n",
       " 'age': 85,\n",
       " 'think': 86,\n",
       " 'far': 87,\n",
       " 'fetched': 88,\n",
       " 'what': 89,\n",
       " 'pity': 90,\n",
       " 'isn': 91,\n",
       " 't': 92,\n",
       " 'story': 93,\n",
       " 'man': 94,\n",
       " 'has': 95,\n",
       " 'unnatural': 96,\n",
       " 'feelings': 97,\n",
       " 'for': 98,\n",
       " 'pig': 99,\n",
       " 'starts': 100,\n",
       " 'out': 101,\n",
       " 'with': 102,\n",
       " 'opening': 103,\n",
       " 'scene': 104,\n",
       " 'terrific': 105,\n",
       " 'example': 106,\n",
       " 'absurd': 107,\n",
       " 'formal': 108,\n",
       " 'orchestra': 109,\n",
       " 'audience': 110,\n",
       " 'turned': 111,\n",
       " 'into': 112,\n",
       " 'an': 113,\n",
       " 'insane': 114,\n",
       " 'violent': 115,\n",
       " 'mob': 116,\n",
       " 'by': 117,\n",
       " 'crazy': 118,\n",
       " 'chantings': 119,\n",
       " 'singers': 120,\n",
       " 'unfortunately': 121,\n",
       " 'stays': 122,\n",
       " 'no': 123,\n",
       " 'general': 124,\n",
       " 'narrative': 125,\n",
       " 'eventually': 126,\n",
       " 'making': 127,\n",
       " 'just': 128,\n",
       " 'too': 129,\n",
       " 'off': 130,\n",
       " 'putting': 131,\n",
       " 'even': 132,\n",
       " 'those': 133,\n",
       " 'from': 134,\n",
       " 'era': 135,\n",
       " 'should': 136,\n",
       " 'be': 137,\n",
       " 'cryptic': 138,\n",
       " 'dialogue': 139,\n",
       " 'would': 140,\n",
       " 'make': 141,\n",
       " 'shakespeare': 142,\n",
       " 'seem': 143,\n",
       " 'easy': 144,\n",
       " 'third': 145,\n",
       " 'grader': 146,\n",
       " 'on': 147,\n",
       " 'technical': 148,\n",
       " 'level': 149,\n",
       " 'better': 150,\n",
       " 'you': 151,\n",
       " 'might': 152,\n",
       " 'good': 153,\n",
       " 'cinematography': 154,\n",
       " 'future': 155,\n",
       " 'great': 156,\n",
       " 'vilmos': 157,\n",
       " 'zsigmond': 158,\n",
       " 'stars': 159,\n",
       " 'sally': 160,\n",
       " 'kirkland': 161,\n",
       " 'frederic': 162,\n",
       " 'forrest': 163,\n",
       " 'seen': 164,\n",
       " 'briefly': 165,\n",
       " 'homelessness': 166,\n",
       " 'or': 167,\n",
       " 'houselessness': 168,\n",
       " 'george': 169,\n",
       " 'carlin': 170,\n",
       " 'stated': 171,\n",
       " 'been': 172,\n",
       " 'issue': 173,\n",
       " 'but': 174,\n",
       " 'never': 175,\n",
       " 'plan': 176,\n",
       " 'help': 177,\n",
       " 'street': 178,\n",
       " 'were': 179,\n",
       " 'once': 180,\n",
       " 'considered': 181,\n",
       " 'human': 182,\n",
       " 'did': 183,\n",
       " 'everything': 184,\n",
       " 'going': 185,\n",
       " 'work': 186,\n",
       " 'vote': 187,\n",
       " 'matter': 188,\n",
       " 'most': 189,\n",
       " 'people': 190,\n",
       " 'homeless': 191,\n",
       " 'lost': 192,\n",
       " 'cause': 193,\n",
       " 'while': 194,\n",
       " 'worrying': 195,\n",
       " 'things': 196,\n",
       " 'racism': 197,\n",
       " 'war': 198,\n",
       " 'iraq': 199,\n",
       " 'pressuring': 200,\n",
       " 'kids': 201,\n",
       " 'succeed': 202,\n",
       " 'technology': 203,\n",
       " 'elections': 204,\n",
       " 'inflation': 205,\n",
       " 'if': 206,\n",
       " 'they': 207,\n",
       " 'll': 208,\n",
       " 'next': 209,\n",
       " 'end': 210,\n",
       " 'up': 211,\n",
       " 'streets': 212,\n",
       " 'br': 213,\n",
       " 'given': 214,\n",
       " 'bet': 215,\n",
       " 'live': 216,\n",
       " 'month': 217,\n",
       " 'without': 218,\n",
       " 'luxuries': 219,\n",
       " 'had': 220,\n",
       " 'home': 221,\n",
       " 'entertainment': 222,\n",
       " 'sets': 223,\n",
       " 'bathroom': 224,\n",
       " 'pictures': 225,\n",
       " 'wall': 226,\n",
       " 'computer': 227,\n",
       " 'treasure': 228,\n",
       " 'like': 229,\n",
       " 'goddard': 230,\n",
       " 'bolt': 231,\n",
       " 'lesson': 232,\n",
       " 'mel': 233,\n",
       " 'brooks': 234,\n",
       " 'directs': 235,\n",
       " 'plays': 236,\n",
       " 'rich': 237,\n",
       " 'world': 238,\n",
       " 'until': 239,\n",
       " 'deciding': 240,\n",
       " 'sissy': 241,\n",
       " 'rival': 242,\n",
       " 'jeffery': 243,\n",
       " 'tambor': 244,\n",
       " 'he': 245,\n",
       " 'thirty': 246,\n",
       " 'days': 247,\n",
       " 'succeeds': 248,\n",
       " 'do': 249,\n",
       " 'wants': 250,\n",
       " 'project': 251,\n",
       " 'more': 252,\n",
       " 'buildings': 253,\n",
       " 'where': 254,\n",
       " 'thrown': 255,\n",
       " 'bracelet': 256,\n",
       " 'his': 257,\n",
       " 'leg': 258,\n",
       " 'monitor': 259,\n",
       " 'every': 260,\n",
       " 'move': 261,\n",
       " 'step': 262,\n",
       " 'sidewalk': 263,\n",
       " 'nickname': 264,\n",
       " 'pepto': 265,\n",
       " 'vagrant': 266,\n",
       " 'after': 267,\n",
       " 'written': 268,\n",
       " 'forehead': 269,\n",
       " 'meets': 270,\n",
       " 'characters': 271,\n",
       " 'including': 272,\n",
       " 'woman': 273,\n",
       " 'name': 274,\n",
       " 'molly': 275,\n",
       " 'lesley': 276,\n",
       " 'ann': 277,\n",
       " 'warren': 278,\n",
       " 'ex': 279,\n",
       " 'dancer': 280,\n",
       " 'got': 281,\n",
       " 'divorce': 282,\n",
       " 'before': 283,\n",
       " 'losing': 284,\n",
       " 'her': 285,\n",
       " 'pals': 286,\n",
       " 'sailor': 287,\n",
       " 'howard': 288,\n",
       " 'morris': 289,\n",
       " 'fumes': 290,\n",
       " 'teddy': 291,\n",
       " 'wilson': 292,\n",
       " 'are': 293,\n",
       " 'already': 294,\n",
       " 'used': 295,\n",
       " 're': 296,\n",
       " 'survivors': 297,\n",
       " 'not': 298,\n",
       " 'reaching': 299,\n",
       " 'mutual': 300,\n",
       " 'agreements': 301,\n",
       " 'being': 302,\n",
       " 'fight': 303,\n",
       " 'flight': 304,\n",
       " 'kill': 305,\n",
       " 'killed': 306,\n",
       " 'love': 307,\n",
       " 'connection': 308,\n",
       " 'between': 309,\n",
       " 'wasn': 310,\n",
       " 'necessary': 311,\n",
       " 'plot': 312,\n",
       " 'found': 313,\n",
       " 'stinks': 314,\n",
       " 'observant': 315,\n",
       " 'films': 316,\n",
       " 'prior': 317,\n",
       " 'shows': 318,\n",
       " 'tender': 319,\n",
       " 'side': 320,\n",
       " 'compared': 321,\n",
       " 'slapstick': 322,\n",
       " 'blazing': 323,\n",
       " 'saddles': 324,\n",
       " 'young': 325,\n",
       " 'frankenstein': 326,\n",
       " 'spaceballs': 327,\n",
       " 'show': 328,\n",
       " 'having': 329,\n",
       " 'something': 330,\n",
       " 'valuable': 331,\n",
       " 'day': 332,\n",
       " 'hand': 333,\n",
       " 'stupid': 334,\n",
       " 'don': 335,\n",
       " 'know': 336,\n",
       " 'money': 337,\n",
       " 'maybe': 338,\n",
       " 'give': 339,\n",
       " 'instead': 340,\n",
       " 'using': 341,\n",
       " 'monopoly': 342,\n",
       " 'this': 343,\n",
       " 'film': 344,\n",
       " 'will': 345,\n",
       " 'inspire': 346,\n",
       " 'others': 347,\n",
       " 'airport': 348,\n",
       " 'brand': 349,\n",
       " 'new': 350,\n",
       " 'luxury': 351,\n",
       " 'plane': 352,\n",
       " 'loaded': 353,\n",
       " 'paintings': 354,\n",
       " 'belonging': 355,\n",
       " 'businessman': 356,\n",
       " 'philip': 357,\n",
       " 'stevens': 358,\n",
       " 'james': 359,\n",
       " 'stewart': 360,\n",
       " 'flying': 361,\n",
       " 'them': 362,\n",
       " 'bunch': 363,\n",
       " 'vip': 364,\n",
       " 'estate': 365,\n",
       " 'preparation': 366,\n",
       " 'opened': 367,\n",
       " 'public': 368,\n",
       " 'museum': 369,\n",
       " 'also': 370,\n",
       " 'board': 371,\n",
       " 'daughter': 372,\n",
       " 'julie': 373,\n",
       " 'kathleen': 374,\n",
       " 'quinlan': 375,\n",
       " 'son': 376,\n",
       " 'jetliner': 377,\n",
       " 'takes': 378,\n",
       " 'planned': 379,\n",
       " 'mid': 380,\n",
       " 'air': 381,\n",
       " 'hi': 382,\n",
       " 'jacked': 383,\n",
       " 'co': 384,\n",
       " 'pilot': 385,\n",
       " 'chambers': 386,\n",
       " 'robert': 387,\n",
       " 'foxworth': 388,\n",
       " 'two': 389,\n",
       " 'accomplice': 390,\n",
       " 'banker': 391,\n",
       " 'monte': 392,\n",
       " 'markham': 393,\n",
       " 'michael': 394,\n",
       " 'pataki': 395,\n",
       " 'knock': 396,\n",
       " 'passengers': 397,\n",
       " 'crew': 398,\n",
       " 'sleeping': 399,\n",
       " 'gas': 400,\n",
       " 'steal': 401,\n",
       " 'cargo': 402,\n",
       " 'land': 403,\n",
       " 'disused': 404,\n",
       " 'strip': 405,\n",
       " 'isolated': 406,\n",
       " 'island': 407,\n",
       " 'descent': 408,\n",
       " 'almost': 409,\n",
       " 'hits': 410,\n",
       " 'oil': 411,\n",
       " 'rig': 412,\n",
       " 'ocean': 413,\n",
       " 'loses': 414,\n",
       " 'control': 415,\n",
       " 'sending': 416,\n",
       " 'crashing': 417,\n",
       " 'sea': 418,\n",
       " 'sinks': 419,\n",
       " 'bottom': 420,\n",
       " 'bang': 421,\n",
       " 'middle': 422,\n",
       " 'bermuda': 423,\n",
       " 'triangle': 424,\n",
       " 'short': 425,\n",
       " 'supply': 426,\n",
       " 'water': 427,\n",
       " 'leaking': 428,\n",
       " 'flown': 429,\n",
       " 'over': 430,\n",
       " 'miles': 431,\n",
       " 'course': 432,\n",
       " 'problems': 433,\n",
       " 'mount': 434,\n",
       " 'survivor': 435,\n",
       " 'await': 436,\n",
       " 'fast': 437,\n",
       " 'running': 438,\n",
       " 'known': 439,\n",
       " 'under': 440,\n",
       " 'slightly': 441,\n",
       " 'different': 442,\n",
       " 'tile': 443,\n",
       " 'second': 444,\n",
       " 'sequel': 445,\n",
       " 'smash': 446,\n",
       " 'hit': 447,\n",
       " 'disaster': 448,\n",
       " 'thriller': 449,\n",
       " 'was': 450,\n",
       " 'directed': 451,\n",
       " 'jerry': 452,\n",
       " 'jameson': 453,\n",
       " 'again': 454,\n",
       " 'predecessors': 455,\n",
       " 'say': 456,\n",
       " 'any': 457,\n",
       " 'sort': 458,\n",
       " 'forgotten': 459,\n",
       " 'entertaining': 460,\n",
       " 'although': 461,\n",
       " 'necessarily': 462,\n",
       " 'reasons': 463,\n",
       " 'three': 464,\n",
       " 'have': 465,\n",
       " 'so': 466,\n",
       " 'actually': 467,\n",
       " 'liked': 468,\n",
       " 'best': 469,\n",
       " 'favourite': 470,\n",
       " 'nice': 471,\n",
       " 'jacking': 472,\n",
       " 'then': 473,\n",
       " 'didn': 474,\n",
       " 'sinking': 475,\n",
       " 'makers': 476,\n",
       " 'trying': 477,\n",
       " 'cross': 478,\n",
       " 'original': 479,\n",
       " 'another': 480,\n",
       " 'popular': 481,\n",
       " 'flick': 482,\n",
       " 'period': 483,\n",
       " 'poseidon': 484,\n",
       " 'adventure': 485,\n",
       " 'submerged': 486,\n",
       " 'stark': 487,\n",
       " 'dilemma': 488,\n",
       " 'facing': 489,\n",
       " 'trapped': 490,\n",
       " 'inside': 491,\n",
       " 'either': 492,\n",
       " 'suffocate': 493,\n",
       " 'runs': 494,\n",
       " 'drown': 495,\n",
       " 'floods': 496,\n",
       " 'doors': 497,\n",
       " 'decent': 498,\n",
       " 'idea': 499,\n",
       " 'could': 500,\n",
       " 'made': 501,\n",
       " 'little': 502,\n",
       " 'bad': 503,\n",
       " 'unsympathetic': 504,\n",
       " 'character': 505,\n",
       " 'dull': 506,\n",
       " 'lethargic': 507,\n",
       " 'set': 508,\n",
       " 'pieces': 509,\n",
       " 'real': 510,\n",
       " 'lack': 511,\n",
       " 'danger': 512,\n",
       " 'suspense': 513,\n",
       " 'tension': 514,\n",
       " 'means': 515,\n",
       " 'missed': 516,\n",
       " 'opportunity': 517,\n",
       " 'rather': 518,\n",
       " 'sluggish': 519,\n",
       " 'keeps': 520,\n",
       " 'entertained': 521,\n",
       " 'odd': 522,\n",
       " 'minutes': 523,\n",
       " 'happens': 524,\n",
       " 'there': 525,\n",
       " 'urgency': 526,\n",
       " 'thought': 527,\n",
       " 'navy': 528,\n",
       " 'become': 529,\n",
       " 'involved': 530,\n",
       " 'pick': 531,\n",
       " 'few': 532,\n",
       " 'shots': 533,\n",
       " 'huge': 534,\n",
       " 'ships': 535,\n",
       " 'helicopters': 536,\n",
       " 'lacking': 537,\n",
       " 'kennedy': 538,\n",
       " 'jinxed': 539,\n",
       " 'airline': 540,\n",
       " 'worker': 541,\n",
       " 'joe': 542,\n",
       " 'patroni': 543,\n",
       " 'back': 544,\n",
       " 'only': 545,\n",
       " 'gets': 546,\n",
       " 'couple': 547,\n",
       " 'scenes': 548,\n",
       " 'barely': 549,\n",
       " 'says': 550,\n",
       " 'anything': 551,\n",
       " 'preferring': 552,\n",
       " 'look': 553,\n",
       " 'worried': 554,\n",
       " 'background': 555,\n",
       " 'video': 556,\n",
       " 'theatrical': 557,\n",
       " 'version': 558,\n",
       " 'run': 559,\n",
       " 'us': 560,\n",
       " 'tv': 561,\n",
       " 'versions': 562,\n",
       " 'add': 563,\n",
       " 'extra': 564,\n",
       " 'hour': 565,\n",
       " 'footage': 566,\n",
       " 'credits': 567,\n",
       " 'sequence': 568,\n",
       " 'flashbacks': 569,\n",
       " 'flesh': 570,\n",
       " 'longer': 571,\n",
       " 'rescue': 572,\n",
       " 'discovery': 573,\n",
       " 'dead': 574,\n",
       " 'bodies': 575,\n",
       " 'navigator': 576,\n",
       " 'am': 577,\n",
       " 'sure': 578,\n",
       " 'sit': 579,\n",
       " 'near': 580,\n",
       " 'cut': 581,\n",
       " 'expected': 582,\n",
       " 'dated': 583,\n",
       " 'badly': 584,\n",
       " 'horrible': 585,\n",
       " 'fashions': 586,\n",
       " 'interior': 587,\n",
       " 'design': 588,\n",
       " 'choices': 589,\n",
       " 'toy': 590,\n",
       " 'model': 591,\n",
       " 'effects': 592,\n",
       " 'aren': 593,\n",
       " 'along': 594,\n",
       " 'sequels': 595,\n",
       " 'pride': 596,\n",
       " 'place': 597,\n",
       " 'razzie': 598,\n",
       " 'award': 599,\n",
       " 'hall': 600,\n",
       " 'shame': 601,\n",
       " 'lots': 602,\n",
       " 'worse': 603,\n",
       " 'reckon': 604,\n",
       " 'harsh': 605,\n",
       " 'action': 606,\n",
       " 'pace': 607,\n",
       " 'slow': 608,\n",
       " 'excitement': 609,\n",
       " 'generated': 610,\n",
       " 'pretty': 611,\n",
       " 'properly': 612,\n",
       " 'production': 613,\n",
       " 'values': 614,\n",
       " 'alright': 615,\n",
       " 'nothing': 616,\n",
       " 'spectacular': 617,\n",
       " 'acting': 618,\n",
       " 'oscar': 619,\n",
       " 'winner': 620,\n",
       " 'jack': 621,\n",
       " 'lemmon': 622,\n",
       " 'said': 623,\n",
       " 'since': 624,\n",
       " 'mistake': 625,\n",
       " 'star': 626,\n",
       " 'looks': 627,\n",
       " 'old': 628,\n",
       " 'frail': 629,\n",
       " 'lee': 630,\n",
       " 'grant': 631,\n",
       " 'drunk': 632,\n",
       " 'sir': 633,\n",
       " 'christopher': 634,\n",
       " 'plenty': 635,\n",
       " 'familiar': 636,\n",
       " 'faces': 637,\n",
       " 'orientated': 638,\n",
       " 'ideas': 639,\n",
       " 'behind': 640,\n",
       " 'bit': 641,\n",
       " 'silly': 642,\n",
       " 'bland': 643,\n",
       " 'direction': 644,\n",
       " 'doesn': 645,\n",
       " 'though': 646,\n",
       " 'sunken': 647,\n",
       " 'shouldn': 648,\n",
       " 'boring': 649,\n",
       " 'followed': 650,\n",
       " 'concorde': 651,\n",
       " 'brilliant': 652,\n",
       " 'dramatic': 653,\n",
       " 'hobo': 654,\n",
       " 'lady': 655,\n",
       " 'ever': 656,\n",
       " 'clothes': 657,\n",
       " 'warehouse': 658,\n",
       " 'none': 659,\n",
       " 'corn': 660,\n",
       " 'face': 661,\n",
       " 'take': 662,\n",
       " 'lawyers': 663,\n",
       " 'superb': 664,\n",
       " 'accused': 665,\n",
       " 'turncoat': 666,\n",
       " 'selling': 667,\n",
       " 'boss': 668,\n",
       " 'dishonest': 669,\n",
       " 'lawyer': 670,\n",
       " 'shrugs': 671,\n",
       " 'indifferently': 672,\n",
       " 'funny': 673,\n",
       " 'words': 674,\n",
       " 'jeffrey': 675,\n",
       " 'favorite': 676,\n",
       " 'later': 677,\n",
       " 'larry': 678,\n",
       " 'sanders': 679,\n",
       " 'fantastic': 680,\n",
       " 'mad': 681,\n",
       " 'millionaire': 682,\n",
       " 'crush': 683,\n",
       " 'ghetto': 684,\n",
       " 'malevolent': 685,\n",
       " 'usual': 686,\n",
       " 'hospital': 687,\n",
       " 'invade': 688,\n",
       " 'demolition': 689,\n",
       " 'site': 690,\n",
       " 'classics': 691,\n",
       " 'legs': 692,\n",
       " 'big': 693,\n",
       " 'diggers': 694,\n",
       " 'fighting': 695,\n",
       " 'bleeds': 696,\n",
       " 'movie': 697,\n",
       " 'each': 698,\n",
       " 'quite': 699,\n",
       " 'often': 700,\n",
       " 'lacked': 701,\n",
       " 'couldn': 702,\n",
       " 'put': 703,\n",
       " 'finger': 704,\n",
       " 'first': 705,\n",
       " 'charisma': 706,\n",
       " 'part': 707,\n",
       " 'leading': 708,\n",
       " 'actress': 709,\n",
       " 'inevitably': 710,\n",
       " 'translated': 711,\n",
       " 'chemistry': 712,\n",
       " 'she': 713,\n",
       " 'shared': 714,\n",
       " 'screen': 715,\n",
       " 'romantic': 716,\n",
       " 'came': 717,\n",
       " 'across': 718,\n",
       " 'merely': 719,\n",
       " 'actors': 720,\n",
       " 'play': 721,\n",
       " 'very': 722,\n",
       " 'well': 723,\n",
       " 'director': 724,\n",
       " 'miscalculated': 725,\n",
       " 'needed': 726,\n",
       " 'screenplay': 727,\n",
       " 'exactly': 728,\n",
       " 'chef': 729,\n",
       " 'seemed': 730,\n",
       " 'enamored': 731,\n",
       " 'culinary': 732,\n",
       " 'skills': 733,\n",
       " 'restaurant': 734,\n",
       " 'ultimately': 735,\n",
       " 'himself': 736,\n",
       " 'youthful': 737,\n",
       " 'exploits': 738,\n",
       " 'anybody': 739,\n",
       " 'else': 740,\n",
       " 'convinced': 741,\n",
       " 'princess': 742,\n",
       " 'disappointed': 743,\n",
       " 'forget': 744,\n",
       " 'nominated': 745,\n",
       " 'judge': 746,\n",
       " 'yourself': 747,\n",
       " 'easily': 748,\n",
       " 'underrated': 749,\n",
       " 'inn': 750,\n",
       " 'cannon': 751,\n",
       " 'its': 752,\n",
       " 'flawed': 753,\n",
       " 'does': 754,\n",
       " 'realistic': 755,\n",
       " 'view': 756,\n",
       " 'unlike': 757,\n",
       " 'how': 758,\n",
       " 'citizen': 759,\n",
       " 'kane': 760,\n",
       " 'gave': 761,\n",
       " 'lounge': 762,\n",
       " 'titanic': 763,\n",
       " 'italians': 764,\n",
       " 'idiots': 765,\n",
       " 'jokes': 766,\n",
       " 'fall': 767,\n",
       " 'flat': 768,\n",
       " 'still': 769,\n",
       " 'lovable': 770,\n",
       " 'way': 771,\n",
       " 'comedies': 772,\n",
       " 'pull': 773,\n",
       " 'traditionally': 774,\n",
       " 'reviled': 775,\n",
       " 'members': 776,\n",
       " 'society': 777,\n",
       " 'truly': 778,\n",
       " 'impressive': 779,\n",
       " 'fisher': 780,\n",
       " 'king': 781,\n",
       " 'crap': 782,\n",
       " 'complaint': 783,\n",
       " 'cast': 784,\n",
       " 'someone': 785,\n",
       " 'writer': 786,\n",
       " 'sorry': 787,\n",
       " 'everyone': 788,\n",
       " 'supposed': 789,\n",
       " 'art': 790,\n",
       " 'wow': 791,\n",
       " 'handed': 792,\n",
       " 'guns': 793,\n",
       " 'screening': 794,\n",
       " 'blow': 795,\n",
       " 'brains': 796,\n",
       " 'watch': 797,\n",
       " 'photographic': 798,\n",
       " 'excellent': 799,\n",
       " 'painful': 800,\n",
       " 'absence': 801,\n",
       " 'sound': 802,\n",
       " 'track': 803,\n",
       " 'brutal': 804,\n",
       " 'loooonnnnng': 805,\n",
       " 'long': 806,\n",
       " 'sitting': 807,\n",
       " 'talking': 808,\n",
       " 'especially': 809,\n",
       " 'complaining': 810,\n",
       " 'really': 811,\n",
       " 'hard': 812,\n",
       " 'getting': 813,\n",
       " 'performances': 814,\n",
       " 'dark': 815,\n",
       " 'sombre': 816,\n",
       " 'uninspired': 817,\n",
       " 'stuff': 818,\n",
       " 'thing': 819,\n",
       " 'maureen': 820,\n",
       " 'stapleton': 821,\n",
       " 'red': 822,\n",
       " 'dress': 823,\n",
       " 'dancing': 824,\n",
       " 'otherwise': 825,\n",
       " 'ripoff': 826,\n",
       " 'bergman': 827,\n",
       " 'fan': 828,\n",
       " 'f': 829,\n",
       " 'anyone': 830,\n",
       " 'enjoyed': 831,\n",
       " 'hours': 832,\n",
       " 'lying': 833,\n",
       " 'typical': 834,\n",
       " 'less': 835,\n",
       " 'movies': 836,\n",
       " 'followable': 837,\n",
       " 'leslie': 838,\n",
       " 'rated': 839,\n",
       " 'moments': 840,\n",
       " 'fleshed': 841,\n",
       " 'probably': 842,\n",
       " 'room': 843,\n",
       " 'worth': 844,\n",
       " 'price': 845,\n",
       " 'rent': 846,\n",
       " 'overall': 847,\n",
       " 'job': 848,\n",
       " 'characteristic': 849,\n",
       " 'speaking': 850,\n",
       " 'directly': 851,\n",
       " 'actor': 852,\n",
       " 'fume': 853,\n",
       " 'both': 854,\n",
       " 'played': 855,\n",
       " 'parts': 856,\n",
       " 'parents': 857,\n",
       " 'took': 858,\n",
       " 'theater': 859,\n",
       " 'interiors': 860,\n",
       " 'watched': 861,\n",
       " 'we': 862,\n",
       " 'walked': 863,\n",
       " 'recently': 864,\n",
       " 'lived': 865,\n",
       " 'rest': 866,\n",
       " 'pretentious': 867,\n",
       " 'ponderous': 868,\n",
       " 'painfully': 869,\n",
       " 'piece': 870,\n",
       " 'wine': 871,\n",
       " 'cheese': 872,\n",
       " 'tripe': 873,\n",
       " 'woody': 874,\n",
       " 'allen': 875,\n",
       " 'directors': 876,\n",
       " 'worst': 877,\n",
       " 'career': 878,\n",
       " 'unmistakable': 879,\n",
       " 'style': 880,\n",
       " 'ingmar': 881,\n",
       " 'berman': 882,\n",
       " 'gives': 883,\n",
       " 'angular': 884,\n",
       " 'muted': 885,\n",
       " 'insight': 886,\n",
       " 'lives': 887,\n",
       " 'family': 888,\n",
       " 'wrought': 889,\n",
       " 'psychological': 890,\n",
       " 'damage': 891,\n",
       " 'caused': 892,\n",
       " 'estrangement': 893,\n",
       " 'non': 894,\n",
       " 'halitosis': 895,\n",
       " 'whatever': 896,\n",
       " 'intentionally': 897,\n",
       " 'comic': 898,\n",
       " 'relief': 899,\n",
       " 'music': 900,\n",
       " 'drenched': 901,\n",
       " 'shadowy': 902,\n",
       " 'pathos': 903,\n",
       " 'defined': 904,\n",
       " 'expressionist': 905,\n",
       " 'nature': 906,\n",
       " 'improvisational': 907,\n",
       " 'method': 908,\n",
       " 'illicit': 909,\n",
       " 'pronounced': 910,\n",
       " 'depth': 911,\n",
       " 'meaning': 912,\n",
       " 'truth': 913,\n",
       " 'beyond': 914,\n",
       " 'simply': 915,\n",
       " 'sympathy': 916,\n",
       " 'felt': 917,\n",
       " 'contempt': 918,\n",
       " 'parade': 919,\n",
       " 'shuffling': 920,\n",
       " 'whining': 921,\n",
       " 'nicotine': 922,\n",
       " 'stained': 923,\n",
       " 'martyrs': 924,\n",
       " 'perpetual': 925,\n",
       " 'quest': 926,\n",
       " 'identity': 927,\n",
       " 'amid': 928,\n",
       " 'backdrop': 929,\n",
       " 'cosmopolitan': 930,\n",
       " 'affluence': 931,\n",
       " 'baked': 932,\n",
       " 'brie': 933,\n",
       " 'intelligentsia': 934,\n",
       " 'looms': 935,\n",
       " 'fart': 936,\n",
       " 'speaks': 937,\n",
       " 'affected': 938,\n",
       " 'platitudes': 939,\n",
       " 'elevated': 940,\n",
       " 'language': 941,\n",
       " 'cigarettes': 942,\n",
       " 'struggling': 943,\n",
       " 'desperate': 944,\n",
       " 'find': 945,\n",
       " 'understanding': 946,\n",
       " 'goes': 947,\n",
       " 'point': 948,\n",
       " 'want': 949,\n",
       " 'slap': 950,\n",
       " 'resolution': 951,\n",
       " 'interminable': 952,\n",
       " 'introspective': 953,\n",
       " 'babble': 954,\n",
       " 'drama': 955,\n",
       " 'taken': 956,\n",
       " 'extreme': 957,\n",
       " 'ability': 958,\n",
       " 'connect': 959,\n",
       " 'chose': 960,\n",
       " 'immersed': 961,\n",
       " 'themselves': 962,\n",
       " 'feel': 963,\n",
       " 'left': 964,\n",
       " 'reason': 965,\n",
       " 'self': 966,\n",
       " 'indulgent': 967,\n",
       " 'spiritually': 968,\n",
       " 'draining': 969,\n",
       " 'insistence': 970,\n",
       " 'promoting': 971,\n",
       " 'message': 972,\n",
       " 'prozac': 973,\n",
       " 'prose': 974,\n",
       " 'distorted': 975,\n",
       " 'techniques': 976,\n",
       " 'jettisons': 977,\n",
       " 'past': 978,\n",
       " 'relevance': 979,\n",
       " 'highly': 980,\n",
       " 'recommend': 981,\n",
       " 'feeling': 982,\n",
       " 'happy': 983,\n",
       " 'need': 984,\n",
       " 'death': 985,\n",
       " 'let': 986,\n",
       " 'pretend': 987,\n",
       " 'happened': 988,\n",
       " 'comedic': 989,\n",
       " 'robin': 990,\n",
       " 'williams': 991,\n",
       " 'nor': 992,\n",
       " 'quirky': 993,\n",
       " 'recent': 994,\n",
       " 'fame': 995,\n",
       " 'hybrid': 996,\n",
       " 'dramatization': 997,\n",
       " 'mixed': 998,\n",
       " 'per': 999,\n",
       " ...}"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Create a dictionary of words in the vocabulary with different indexes for every word\n",
    "# This will be applied to the input layer\n",
    "\n",
    "word2index = {}\n",
    "for i,word in enumerate(vocab):\n",
    "    word2index[word] = i\n",
    "    \n",
    "# display the map of words to indices\n",
    "word2index"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Input Layer Transformation\n",
    "Convert the input layer to have unique words and number of times it appeared in given review"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def update_input_layer(review):\n",
    "    \n",
    "    global layer_0\n",
    "    # clear out previous state by resetting the layer to be all 0s\n",
    "    layer_0 *= 0\n",
    "    \n",
    "    # TODO: count how many times each word is used in the given review and store the results in layer_0 \n",
    "    for word in review.split(\" \"):\n",
    "        layer_0[0][word2index[word]] += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "update_input_layer(reviews[0])\n",
    "layer_0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Convert positive to 1 and negative to 0\n",
    "def get_target_for_label(label):\n",
    "\n",
    "    if (label == 'POSITIVE'):\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Created a set to store only unique elements from the reviews variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_vocab = set()\n",
    "for review in reviews:\n",
    "    for words in review.split(\" \"):\n",
    "        review_vocab.add(words)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_vocab = set()\n",
    "for label in labels:\n",
    "    label_vocab.add(label)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building a Neural Network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# Encapsulate our neural network in a class\n",
    "class SentimentNetwork:\n",
    "    def __init__(self, reviews,labels,hidden_nodes = 10, learning_rate = 0.1):\n",
    "       \n",
    "        # Assign a seed to our random number generator to ensure we get\n",
    "        # reproducable results during development \n",
    "        np.random.seed(1)\n",
    "\n",
    "        # process the reviews and their associated labels so that everything\n",
    "        # is ready for training\n",
    "        self.pre_process_data(reviews, labels)\n",
    "        \n",
    "        # Build the network to have the number of hidden nodes and the learning rate that\n",
    "        # were passed into this initializer. Make the same number of input nodes as\n",
    "        # there are vocabulary words and create a single output node.\n",
    "        self.init_network(len(self.review_vocab),hidden_nodes, 1, learning_rate)\n",
    "\n",
    "    def pre_process_data(self, reviews, labels):\n",
    "        \n",
    "        # Create a set of review_vocab which contains all unique words from the train dataset\n",
    "        review_vocab = set()\n",
    "        for review in reviews:\n",
    "            for word in review.split(\" \"):\n",
    "                review_vocab.add(word)\n",
    "\n",
    "        # Convert the vocabulary set to a list so we can access words via indices\n",
    "        self.review_vocab = list(review_vocab)\n",
    "        \n",
    "        # Similary create a set for label as well. It will have only 2 Positive and Negative values\n",
    "        label_vocab = set()\n",
    "        for label in labels:\n",
    "            label_vocab.add(label)\n",
    "        \n",
    "        # Convert the label vocabulary set to a list so we can access labels via indices\n",
    "        self.label_vocab = list(label_vocab)\n",
    "        \n",
    "        # Store the sizes of the review and label vocabularies.\n",
    "        self.review_vocab_size = len(self.review_vocab)\n",
    "        self.label_vocab_size = len(self.label_vocab)\n",
    "        \n",
    "        # Create a dictionary of words in the vocabulary mapped to index positions\n",
    "        self.word2index = {}\n",
    "        for i, word in enumerate(self.review_vocab):\n",
    "            self.word2index[word] = i\n",
    "        \n",
    "        # Create a dictionary of labels mapped to index positions\n",
    "        self.label2index = {}\n",
    "        for i, label in enumerate(self.label_vocab):\n",
    "            self.label2index[label] = i\n",
    "        \n",
    "    def init_network(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        # Set number of nodes in input, hidden and output layers.\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "\n",
    "        # Store the learning rate\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Initialize weights\n",
    "\n",
    "        # weights between the input layer and the hidden layer.\n",
    "        self.weights_0_1 = np.zeros((self.input_nodes,self.hidden_nodes))\n",
    "    \n",
    "        # weights between the hidden layer and the output layer.\n",
    "        self.weights_1_2 = np.random.normal(0.0, self.output_nodes**-0.5, \n",
    "                                                (self.hidden_nodes, self.output_nodes))\n",
    "        \n",
    "        # Create input layer with zeroes intially\n",
    "        self.layer_0 = np.zeros((1,input_nodes))\n",
    "    \n",
    "        # Create a function to update the input layer with word and its frequency of occurence in the given review\n",
    "        # as a input layer\n",
    "    def update_input_layer(self,review):\n",
    "\n",
    "        # clear out previous state, reset the layer to be all 0s\n",
    "        self.layer_0 *= 0\n",
    "        \n",
    "        for word in review.split(\" \"):\n",
    "            if(word in self.word2index.keys()):\n",
    "                self.layer_0[0][self.word2index[word]] += 1\n",
    "                \n",
    "        # Create a function to convert labels to 1 and 0\n",
    "    def get_target_for_label(self,label):\n",
    "        if(label == 'POSITIVE'):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "        # Create a function sigmoid for activation function\n",
    "    def sigmoid(self,x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "        # Sigmoid Derivative function for the error terms\n",
    "    def sigmoid_output_2_derivative(self,output):\n",
    "        return output * (1 - output)\n",
    "    \n",
    "    def train(self, training_reviews, training_labels):\n",
    "        \n",
    "        # make sure out we have a matching number of reviews and labels\n",
    "        assert(len(training_reviews) == len(training_labels))\n",
    "        \n",
    "        # Keep track of correct predictions to display accuracy during training \n",
    "        correct_so_far = 0\n",
    "\n",
    "        # Remember when we started for printing time statistics\n",
    "        start = time.time()\n",
    "        \n",
    "        # loop through all the given reviews and run a forward and backward pass,\n",
    "        # updating weights for every item\n",
    "        for i in range(len(training_reviews)):\n",
    "            \n",
    "            # Get the next review and its correct label\n",
    "            review = training_reviews[i]\n",
    "            label = training_labels[i]\n",
    "            \n",
    "            #Neural Network Forward Pass\n",
    "\n",
    "            # Convert the input layer to required output using the function\n",
    "            self.update_input_layer(review)\n",
    "\n",
    "            # Hidden layer \n",
    "            layer_1 = self.layer_0.dot(self.weights_0_1)\n",
    "\n",
    "            # Output layer\n",
    "            layer_2 = self.sigmoid(layer_1.dot(self.weights_1_2))\n",
    "            \n",
    "            # Neural network Backward Pass\n",
    "\n",
    "            # Output error\n",
    "            layer_2_error = layer_2 - self.get_target_for_label(label) \n",
    "            layer_2_delta = layer_2_error * self.sigmoid_output_2_derivative(layer_2)\n",
    "\n",
    "            # Hidden error\n",
    "            layer_1_error = layer_2_delta.dot(self.weights_1_2.T) \n",
    "            layer_1_delta = layer_1_error \n",
    "\n",
    "            # Update the weights using gradient descent\n",
    "            self.weights_1_2 -= layer_1.T.dot(layer_2_delta) * self.learning_rate \n",
    "            self.weights_0_1 -= self.layer_0.T.dot(layer_1_delta) * self.learning_rate \n",
    "\n",
    "            # Keep track of correct predictions.\n",
    "            if(layer_2 >= 0.5 and label == 'POSITIVE'):\n",
    "                correct_so_far += 1\n",
    "            elif(layer_2 < 0.5 and label == 'NEGATIVE'):\n",
    "                correct_so_far += 1\n",
    "            \n",
    "            # print out our prediction accuracy and speed \n",
    "            # throughout the training process. \n",
    "            elapsed_time = float(time.time() - start)\n",
    "            reviews_per_second = i / elapsed_time if elapsed_time > 0 else 0\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(training_reviews)))[:4] \\\n",
    "                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n",
    "                             + \" #Correct:\" + str(correct_so_far) + \" #Trained:\" + str(i+1) \\\n",
    "                             + \" Training Accuracy:\" + str(correct_so_far * 100 / float(i+1))[:4] + \"%\")\n",
    "            if(i % 2500 == 0):\n",
    "                print(\"\")\n",
    "    \n",
    "    def test(self, testing_reviews, testing_labels):\n",
    "        \n",
    "        # keep track of how many correct predictions we make\n",
    "        correct = 0\n",
    "\n",
    "        # we'll time how many predictions per second we make\n",
    "        start = time.time()\n",
    "\n",
    "        # Loop through each of the given reviews and call run to predict\n",
    "        # its label. \n",
    "        for i in range(len(testing_reviews)):\n",
    "            pred = self.run(testing_reviews[i])\n",
    "            if(pred == testing_labels[i]):\n",
    "                correct += 1\n",
    "            \n",
    "            # For debug purposes, print out our prediction accuracy and speed \n",
    "            # throughout the prediction process. \n",
    "\n",
    "            elapsed_time = float(time.time() - start)\n",
    "            reviews_per_second = i / elapsed_time if elapsed_time > 0 else 0\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(testing_reviews)))[:4] \\\n",
    "                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n",
    "                             + \" #Correct:\" + str(correct) + \" #Tested:\" + str(i+1) \\\n",
    "                             + \" Testing Accuracy:\" + str(correct * 100 / float(i+1))[:4] + \"%\")\n",
    "    \n",
    "    def run(self, review):\n",
    " \n",
    "        # Input Layer\n",
    "        self.update_input_layer(review.lower())\n",
    "\n",
    "        # Hidden layer\n",
    "        layer_1 = self.layer_0.dot(self.weights_0_1)\n",
    "\n",
    "        # Output layer\n",
    "        layer_2 = self.sigmoid(layer_1.dot(self.weights_1_2))\n",
    "        \n",
    "        # Return POSITIVE for values above greater-than-or-equal-to 0.5 in the output layer;\n",
    "        # return NEGATIVE for other values\n",
    "        if(layer_2[0] >= 0.5):\n",
    "            return \"POSITIVE\"\n",
    "        else:\n",
    "            return \"NEGATIVE\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train the model and check for training accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:0.0% Speed(reviews/sec):0.0 #Correct:1 #Trained:1 Training Accuracy:100.%\n",
      "Progress:10.4% Speed(reviews/sec):77.68 #Correct:1248 #Trained:2501 Training Accuracy:49.9%\n",
      "Progress:20.8% Speed(reviews/sec):75.65 #Correct:2498 #Trained:5001 Training Accuracy:49.9%\n",
      "Progress:31.2% Speed(reviews/sec):77.48 #Correct:3748 #Trained:7501 Training Accuracy:49.9%\n",
      "Progress:41.6% Speed(reviews/sec):77.16 #Correct:4998 #Trained:10001 Training Accuracy:49.9%\n",
      "Progress:52.0% Speed(reviews/sec):77.35 #Correct:6248 #Trained:12501 Training Accuracy:49.9%\n",
      "Progress:62.5% Speed(reviews/sec):77.65 #Correct:7491 #Trained:15001 Training Accuracy:49.9%\n",
      "Progress:70.0% Speed(reviews/sec):77.32 #Correct:8413 #Trained:16823 Training Accuracy:50.0%"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.6/site-packages/ipykernel_launcher.py:105: RuntimeWarning: overflow encountered in exp\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:72.9% Speed(reviews/sec):77.34 #Correct:8752 #Trained:17501 Training Accuracy:50.0%\n",
      "Progress:83.3% Speed(reviews/sec):76.91 #Correct:10001 #Trained:20001 Training Accuracy:50.0%\n",
      "Progress:93.7% Speed(reviews/sec):76.30 #Correct:11251 #Trained:22501 Training Accuracy:50.0%\n",
      "Progress:99.9% Speed(reviews/sec):76.50 #Correct:12001 #Trained:24000 Training Accuracy:50.0%"
     ]
    }
   ],
   "source": [
    "mlp = SentimentNetwork(reviews[:-1000],labels[:-1000], learning_rate=0.01)\n",
    "mlp.train(reviews[:-1000],labels[:-1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Since the accuracy is at 50% try reducing the learning rate to 0.001 and check the output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:0.0% Speed(reviews/sec):0.0 #Correct:1 #Trained:1 Training Accuracy:100.%\n",
      "Progress:10.4% Speed(reviews/sec):213.5 #Correct:1266 #Trained:2501 Training Accuracy:50.6%\n",
      "Progress:20.8% Speed(reviews/sec):206.0 #Correct:2636 #Trained:5001 Training Accuracy:52.7%\n",
      "Progress:31.2% Speed(reviews/sec):206.1 #Correct:4063 #Trained:7501 Training Accuracy:54.1%\n",
      "Progress:41.6% Speed(reviews/sec):204.8 #Correct:5593 #Trained:10001 Training Accuracy:55.9%\n",
      "Progress:52.0% Speed(reviews/sec):203.1 #Correct:7156 #Trained:12501 Training Accuracy:57.2%\n",
      "Progress:62.5% Speed(reviews/sec):202.9 #Correct:8763 #Trained:15001 Training Accuracy:58.4%\n",
      "Progress:72.9% Speed(reviews/sec):203.0 #Correct:10407 #Trained:17501 Training Accuracy:59.4%\n",
      "Progress:83.3% Speed(reviews/sec):201.8 #Correct:12042 #Trained:20001 Training Accuracy:60.2%\n",
      "Progress:93.7% Speed(reviews/sec):200.9 #Correct:13745 #Trained:22501 Training Accuracy:61.0%\n",
      "Progress:99.9% Speed(reviews/sec):200.8 #Correct:14807 #Trained:24000 Training Accuracy:61.6%"
     ]
    }
   ],
   "source": [
    "mlp = SentimentNetwork(reviews[:-1000],labels[:-1000], learning_rate=0.001)\n",
    "mlp.train(reviews[:-1000],labels[:-1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Even with learning rate at 0.001 the accuracy achived is only 62% which is not good"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reducing Noise in Our Input Data\n",
    "\n",
    "Previously in the input layer we are using how many times each word is used in the review. Words like the , a, . have high counts\n",
    "and have a bad effect on weights. We will change the input layer to have 1 and 0, 1 if the word is present and 0 if word\n",
    "is not present and lets test the accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "import time\n",
    "import sys\n",
    "import numpy as np\n",
    "\n",
    "# Encapsulate our neural network in a class\n",
    "class SentimentNetwork:\n",
    "    def __init__(self, reviews,labels,hidden_nodes = 10, learning_rate = 0.1):\n",
    "        \n",
    "        # Assign a seed to our random number generator to ensure we get\n",
    "        # reproducable results during development \n",
    "        np.random.seed(1)\n",
    "\n",
    "        # process the reviews and their associated labels so that everything\n",
    "        # is ready for training\n",
    "        self.pre_process_data(reviews, labels)\n",
    "        \n",
    "        # Build the network to have the number of hidden nodes and the learning rate that\n",
    "        # were passed into this initializer. Make the same number of input nodes as\n",
    "        # there are vocabulary words and create a single output node.\n",
    "        self.init_network(len(self.review_vocab),hidden_nodes, 1, learning_rate)\n",
    "\n",
    "    def pre_process_data(self, reviews, labels):\n",
    "        \n",
    "        # populate review_vocab with all of the words in the given reviews\n",
    "        review_vocab = set()\n",
    "        for review in reviews:\n",
    "            for word in review.split(\" \"):\n",
    "                review_vocab.add(word)\n",
    "\n",
    "        # Convert the vocabulary set to a list so we can access words via indices\n",
    "        self.review_vocab = list(review_vocab)\n",
    "        \n",
    "        # populate label_vocab with all of the words in the given labels.\n",
    "        label_vocab = set()\n",
    "        for label in labels:\n",
    "            label_vocab.add(label)\n",
    "        \n",
    "        # Convert the label vocabulary set to a list so we can access labels via indices\n",
    "        self.label_vocab = list(label_vocab)\n",
    "        \n",
    "        # Store the sizes of the review and label vocabularies.\n",
    "        self.review_vocab_size = len(self.review_vocab)\n",
    "        self.label_vocab_size = len(self.label_vocab)\n",
    "        \n",
    "        # Create a dictionary of words in the vocabulary mapped to index positions\n",
    "        self.word2index = {}\n",
    "        for i, word in enumerate(self.review_vocab):\n",
    "            self.word2index[word] = i\n",
    "        \n",
    "        # Create a dictionary of labels mapped to index positions\n",
    "        self.label2index = {}\n",
    "        for i, label in enumerate(self.label_vocab):\n",
    "            self.label2index[label] = i\n",
    "        \n",
    "    def init_network(self, input_nodes, hidden_nodes, output_nodes, learning_rate):\n",
    "        # Set number of nodes in input, hidden and output layers.\n",
    "        self.input_nodes = input_nodes\n",
    "        self.hidden_nodes = hidden_nodes\n",
    "        self.output_nodes = output_nodes\n",
    "\n",
    "        # Store the learning rate\n",
    "        self.learning_rate = learning_rate\n",
    "\n",
    "        # Initialize weights\n",
    "\n",
    "        # These are the weights between the input layer and the hidden layer.\n",
    "        self.weights_0_1 = np.zeros((self.input_nodes,self.hidden_nodes))\n",
    "    \n",
    "        # These are the weights between the hidden layer and the output layer.\n",
    "        self.weights_1_2 = np.random.normal(0.0, self.output_nodes**-0.5, \n",
    "                                                (self.hidden_nodes, self.output_nodes))\n",
    "        \n",
    "        # The input layer, a two-dimensional matrix with shape 1 x input_nodes\n",
    "        self.layer_0 = np.zeros((1,input_nodes))\n",
    "    \n",
    "    \n",
    "        # Updating the function to transform the input layer which will have 1 and 0 if present or not present\n",
    "        # instead of number of times it appears in the review\n",
    "    def update_input_layer(self,review):\n",
    "\n",
    "        # clear out previous state, reset the layer to be all 0s\n",
    "        self.layer_0 *= 0\n",
    "        \n",
    "        for word in review.split(\" \"):\n",
    "           \n",
    "            if(word in self.word2index.keys()):\n",
    "                self.layer_0[0][self.word2index[word]] = 1\n",
    "                \n",
    "    def get_target_for_label(self,label):\n",
    "        if(label == 'POSITIVE'):\n",
    "            return 1\n",
    "        else:\n",
    "            return 0\n",
    "        \n",
    "    def sigmoid(self,x):\n",
    "        return 1 / (1 + np.exp(-x))\n",
    "    \n",
    "    def sigmoid_output_2_derivative(self,output):\n",
    "        return output * (1 - output)\n",
    "    \n",
    "    def train(self, training_reviews, training_labels):\n",
    "        \n",
    "        # make sure out we have a matching number of reviews and labels\n",
    "        assert(len(training_reviews) == len(training_labels))\n",
    "        \n",
    "        # Keep track of correct predictions to display accuracy during training \n",
    "        correct_so_far = 0\n",
    "\n",
    "        # Remember when we started for printing time statistics\n",
    "        start = time.time()\n",
    "        \n",
    "        # loop through all the given reviews and run a forward and backward pass,\n",
    "        # updating weights for every item\n",
    "        for i in range(len(training_reviews)):\n",
    "            \n",
    "            # Get the next review and its correct label\n",
    "            review = training_reviews[i]\n",
    "            label = training_labels[i]\n",
    "            \n",
    "            # Neural Network forward pass\n",
    "\n",
    "            # Input Layer\n",
    "            self.update_input_layer(review)\n",
    "\n",
    "            # Hidden layer\n",
    "            layer_1 = self.layer_0.dot(self.weights_0_1)\n",
    "\n",
    "            # Output layer\n",
    "            layer_2 = self.sigmoid(layer_1.dot(self.weights_1_2))\n",
    "            \n",
    "            # Neural Network Backward pass\n",
    "\n",
    "            # Output error\n",
    "            layer_2_error = layer_2 - self.get_target_for_label(label) # Output layer error is the difference between desired target and actual output.\n",
    "            layer_2_delta = layer_2_error * self.sigmoid_output_2_derivative(layer_2)\n",
    "\n",
    "            # Backpropagated error\n",
    "            layer_1_error = layer_2_delta.dot(self.weights_1_2.T) # errors propagated to the hidden layer\n",
    "            layer_1_delta = layer_1_error # hidden layer gradients - no nonlinearity so it's the same as the error\n",
    "\n",
    "            # Update the weights\n",
    "            self.weights_1_2 -= layer_1.T.dot(layer_2_delta) * self.learning_rate # update hidden-to-output weights with gradient descent step\n",
    "            self.weights_0_1 -= self.layer_0.T.dot(layer_1_delta) * self.learning_rate # update input-to-hidden weights with gradient descent step\n",
    "\n",
    "            # Keep track of correct predictions.\n",
    "            if(layer_2 >= 0.5 and label == 'POSITIVE'):\n",
    "                correct_so_far += 1\n",
    "            elif(layer_2 < 0.5 and label == 'NEGATIVE'):\n",
    "                correct_so_far += 1\n",
    "            \n",
    "            # For debug purposes, print out our prediction accuracy and speed \n",
    "            # throughout the training process. \n",
    "            elapsed_time = float(time.time() - start)\n",
    "            reviews_per_second = i / elapsed_time if elapsed_time > 0 else 0\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(training_reviews)))[:4] \\\n",
    "                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n",
    "                             + \" #Correct:\" + str(correct_so_far) + \" #Trained:\" + str(i+1) \\\n",
    "                             + \" Training Accuracy:\" + str(correct_so_far * 100 / float(i+1))[:4] + \"%\")\n",
    "            if(i % 2500 == 0):\n",
    "                print(\"\")\n",
    "    \n",
    "    def test(self, testing_reviews, testing_labels):\n",
    "        \n",
    "        \n",
    "        # keep track of how many correct predictions we make\n",
    "        correct = 0\n",
    "\n",
    "        # we'll time how many predictions per second we make\n",
    "        start = time.time()\n",
    "\n",
    "        # Loop through each of the given reviews and call run to predict\n",
    "        # its label. \n",
    "        for i in range(len(testing_reviews)):\n",
    "            pred = self.run(testing_reviews[i])\n",
    "            if(pred == testing_labels[i]):\n",
    "                correct += 1\n",
    "            \n",
    "            # For debug purposes, print out our prediction accuracy and speed \n",
    "            # throughout the prediction process. \n",
    "\n",
    "            elapsed_time = float(time.time() - start)\n",
    "            reviews_per_second = i / elapsed_time if elapsed_time > 0 else 0\n",
    "            \n",
    "            sys.stdout.write(\"\\rProgress:\" + str(100 * i/float(len(testing_reviews)))[:4] \\\n",
    "                             + \"% Speed(reviews/sec):\" + str(reviews_per_second)[0:5] \\\n",
    "                             + \" #Correct:\" + str(correct) + \" #Tested:\" + str(i+1) \\\n",
    "                             + \" Testing Accuracy:\" + str(correct * 100 / float(i+1))[:4] + \"%\")\n",
    "    \n",
    "    def run(self, review):\n",
    "        \"\"\"\n",
    "        Returns a POSITIVE or NEGATIVE prediction for the given review.\n",
    "        \"\"\"\n",
    "        # Run a forward pass through the network, like in the \"train\" function.\n",
    "        \n",
    "        # Input Layer\n",
    "        self.update_input_layer(review.lower())\n",
    "\n",
    "        # Hidden layer\n",
    "        layer_1 = self.layer_0.dot(self.weights_0_1)\n",
    "\n",
    "        # Output layer\n",
    "        layer_2 = self.sigmoid(layer_1.dot(self.weights_1_2))\n",
    "        \n",
    "        # Return POSITIVE for values above greater-than-or-equal-to 0.5 in the output layer;\n",
    "        # return NEGATIVE for other values\n",
    "        if(layer_2[0] >= 0.5):\n",
    "            return \"POSITIVE\"\n",
    "        else:\n",
    "            return \"NEGATIVE\"\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Now based on the below output we can clearly see the accuracy has increased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Progress:0.0% Speed(reviews/sec):0.0 #Correct:1 #Trained:1 Training Accuracy:100.%\n",
      "Progress:10.4% Speed(reviews/sec):74.99 #Correct:1824 #Trained:2501 Training Accuracy:72.9%\n",
      "Progress:20.8% Speed(reviews/sec):74.58 #Correct:3818 #Trained:5001 Training Accuracy:76.3%\n",
      "Progress:31.2% Speed(reviews/sec):74.59 #Correct:5915 #Trained:7501 Training Accuracy:78.8%\n",
      "Progress:41.6% Speed(reviews/sec):74.30 #Correct:8052 #Trained:10001 Training Accuracy:80.5%\n",
      "Progress:52.0% Speed(reviews/sec):74.43 #Correct:10177 #Trained:12501 Training Accuracy:81.4%\n",
      "Progress:62.5% Speed(reviews/sec):73.95 #Correct:12312 #Trained:15001 Training Accuracy:82.0%\n",
      "Progress:72.9% Speed(reviews/sec):73.87 #Correct:14423 #Trained:17501 Training Accuracy:82.4%\n",
      "Progress:83.3% Speed(reviews/sec):74.08 #Correct:16588 #Trained:20001 Training Accuracy:82.9%\n",
      "Progress:93.7% Speed(reviews/sec):73.98 #Correct:18768 #Trained:22501 Training Accuracy:83.4%\n",
      "Progress:99.9% Speed(reviews/sec):73.94 #Correct:20097 #Trained:24000 Training Accuracy:83.7%"
     ]
    }
   ],
   "source": [
    "mlp = SentimentNetwork(reviews[:-1000],labels[:-1000], learning_rate=0.1)\n",
    "mlp.train(reviews[:-1000],labels[:-1000])"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
